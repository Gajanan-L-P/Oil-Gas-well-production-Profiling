{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import keras\n",
    "import argparse\n",
    "import scipy.io\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.regularizers import L1L2\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (7,20,23,25,34,48,65,83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Load dataset\n",
    "master_data= pd.read_csv('/home/affine/Downloads/Deep_Learning/demo/demo/TGS/tgs-data-science-master-c3f8b3a2900f40ddde655f8ef5f17d00cfaa7033/data/Master_dataset_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'WellId', 'LeaseId', 'GroupId', 'API', 'FieldName_x',\n",
       "       'Well Name and Number', 'WellNumber_x', 'OperatorName_x', 'StateName_x',\n",
       "       'County_x', 'ProductionMonthYear', 'DaysOnProduction', 'Gas', 'Oil',\n",
       "       'Water', 'ProductionType', 'ProductionTypeName', 'WellsReported',\n",
       "       'AllocationMethod', 'DisplayFormation_x', 'StateLeaseId', 'WellName',\n",
       "       'WellNumber_y', 'BasinName', 'DisplayFormation_y', 'Township',\n",
       "       'TownshipDirection', 'Range', 'RangeDirection', 'Section', 'District',\n",
       "       'Abstract', 'Survey', 'Block', 'Offshore', 'Area', 'OffshoreBlock',\n",
       "       'QuarterQuarter', 'FootageNS', 'DirectionNS', 'FootageEW',\n",
       "       'DirectionEW', 'SurfaceLatitude', 'SurfaceLongitude', 'BottomLatitude',\n",
       "       'BottomLongitude', 'SpudDate', 'PlugDate', 'CompletionDate',\n",
       "       'FirstProductionDate', 'FirstMonth', 'HasProduction', 'WellType',\n",
       "       'TotalVerticalDepth', 'MeasuredDepth', 'ElevationGround',\n",
       "       'ElevationKellyBushing', 'ElevationWaterDepth', 'WellStatus',\n",
       "       'CurrentLeaseName', 'CalculatedMajorPhase', 'DisplayLocation', 'Slant',\n",
       "       'HasWellProduction', 'LocationDescription', 'MeridianName',\n",
       "       'SymbolName', 'MeridianId', 'APIState', 'APICounty', 'DisplayElevation',\n",
       "       'StateWellID', 'Top', 'Bottom', 'ProductionMonthYear1', 'YearMonth',\n",
       "       'unique', 'Oil_test', 'Gas_test', 'Water_test', 'GOR', 'TestDuration',\n",
       "       'Method', 'CasingPressure', 'ShutInPressure', 'GasGravity',\n",
       "       'OilGravity', 'FTP', 'WellID_API'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns in dataset\n",
    "master_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting Operator 'Occidental W TX OVERTHRUST INC.'\n",
    "master_data1=master_data[master_data.OperatorName_x==\"OCCIDENTAL W TX OVERTHRUST INC.\"]\n",
    "#master_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select required API\n",
    "master_data1=master_data1[master_data1.API==42371383490000]#42371381890000]#42371380040000]#42371381890000]#42371381890000]#42371378930000]\n",
    "labels=['Oil','ProductionMonthYear1','YearMonth']\n",
    "master_data1=master_data1[labels]\n",
    "\n",
    "#Sort data based on YearMonth\n",
    "master_data1=master_data1.sort_values(by=['YearMonth'])#, ascending=[1, 1],axis=1)\n",
    "#master_data1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data2=master_data1\n",
    "master_data2=pd.DataFrame(master_data2)\n",
    "# master_data2['start_date']=datetime.strptime(master_data1['ProductionMonthYear1'].iloc[0], \"%Y-%m-%d\")\n",
    "# print(type(pd.DataFrame(master_data2['start_date']).iloc[0,0]))\n",
    "# print(type(pd.DataFrame(master_data2['ProductionMonthYear1']).iloc[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_data2['ProductionMonthYear1']=master_data2['ProductionMonthYear1'].map(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "# master_data2['days_age']=master_data2['ProductionMonthYear1'].sub(master_data2['start_date'])\n",
    "# master_data2['days_age']=master_data2['days_age']/np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oil</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearMonth</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200810</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200811</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200812</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200901</th>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200902</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200903</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200904</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200905</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200906</th>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200907</th>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200908</th>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200909</th>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200910</th>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200911</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200912</th>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201001</th>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201002</th>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201003</th>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201004</th>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201005</th>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201006</th>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201007</th>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201008</th>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201009</th>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201010</th>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201011</th>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201012</th>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101</th>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201102</th>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201103</th>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201503</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201504</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201505</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201506</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201507</th>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201508</th>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201509</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201510</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201511</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201512</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201606</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201607</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201608</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201609</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201610</th>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201612</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201702</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201703</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201704</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201705</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201706</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201707</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201708</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Oil\n",
       "YearMonth       \n",
       "200810       0.0\n",
       "200811       0.0\n",
       "200812       0.0\n",
       "200901     107.0\n",
       "200902      10.0\n",
       "200903       0.0\n",
       "200904       0.0\n",
       "200905       0.0\n",
       "200906     128.0\n",
       "200907     140.0\n",
       "200908      80.0\n",
       "200909      81.0\n",
       "200910     103.0\n",
       "200911     160.0\n",
       "200912      69.0\n",
       "201001      90.0\n",
       "201002      96.0\n",
       "201003      90.0\n",
       "201004      80.0\n",
       "201005     145.0\n",
       "201006      67.0\n",
       "201007      26.0\n",
       "201008     113.0\n",
       "201009     103.0\n",
       "201010     116.0\n",
       "201011      90.0\n",
       "201012      92.0\n",
       "201101      90.0\n",
       "201102      28.0\n",
       "201103      61.0\n",
       "...          ...\n",
       "201503      22.0\n",
       "201504       9.0\n",
       "201505      15.0\n",
       "201506      14.0\n",
       "201507      25.0\n",
       "201508      28.0\n",
       "201509      23.0\n",
       "201510      27.0\n",
       "201511      10.0\n",
       "201512      13.0\n",
       "201601      14.0\n",
       "201602       8.0\n",
       "201603      15.0\n",
       "201604      34.0\n",
       "201605      20.0\n",
       "201606      18.0\n",
       "201607      19.0\n",
       "201608       7.0\n",
       "201609       6.0\n",
       "201610      26.0\n",
       "201611      15.0\n",
       "201612      20.0\n",
       "201701      21.0\n",
       "201702      18.0\n",
       "201703      22.0\n",
       "201704      18.0\n",
       "201705      11.0\n",
       "201706      13.0\n",
       "201707       5.0\n",
       "201708      11.0\n",
       "\n",
       "[107 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set YearMonth as Index for production\n",
    "master_data2=master_data2[['YearMonth','Oil']]#,'days_age']]\n",
    "master_data2=master_data2.iloc[:-1,:]# removing 201708 & 201709 values as they were zeros\n",
    "master_data2.set_index('YearMonth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24f4b5d438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "dataset = master_data2\n",
    "values = dataset.values\n",
    "\n",
    "# specify columns to plot\n",
    "groups = [0,1]#,2]#3,4]#,5,6,7,8,9,10]\n",
    "i = 0\n",
    "# plot each column\n",
    "pyplot.figure()\n",
    "for group in groups:\n",
    "    pyplot.subplot(len(groups), 1, i+1)\n",
    "    pyplot.plot(values[:, group])\n",
    "    pyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "    i += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define lag(time steps for training) and n_seq(number of time steps to be predicted in future)\n",
    "n_seq = 12\n",
    "n_feature=1\n",
    "n_lag= 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 1)\n",
      "    var1(t-18)  var1(t-17)  var1(t-16)  var1(t-15)  var1(t-14)  var1(t-13)  \\\n",
      "18     0.00000     0.00000     0.00000     0.66875      0.0625       0.000   \n",
      "19     0.00000     0.00000     0.66875     0.06250      0.0000       0.000   \n",
      "20     0.00000     0.66875     0.06250     0.00000      0.0000       0.000   \n",
      "21     0.66875     0.06250     0.00000     0.00000      0.0000       0.800   \n",
      "22     0.06250     0.00000     0.00000     0.00000      0.8000       0.875   \n",
      "\n",
      "    var1(t-12)  var1(t-11)  var1(t-10)  var1(t-9)     ...      var1(t+2)  \\\n",
      "18       0.000     0.00000     0.80000    0.87500     ...        0.41875   \n",
      "19       0.000     0.80000     0.87500    0.50000     ...        0.16250   \n",
      "20       0.800     0.87500     0.50000    0.50625     ...        0.70625   \n",
      "21       0.875     0.50000     0.50625    0.64375     ...        0.64375   \n",
      "22       0.500     0.50625     0.64375    1.00000     ...        0.72500   \n",
      "\n",
      "    var1(t+3)  var1(t+4)  var1(t+5)  var1(t+6)  var1(t+7)  var1(t+8)  \\\n",
      "18    0.16250    0.70625    0.64375     0.7250    0.56250    0.57500   \n",
      "19    0.70625    0.64375    0.72500     0.5625    0.57500    0.56250   \n",
      "20    0.64375    0.72500    0.56250     0.5750    0.56250    0.17500   \n",
      "21    0.72500    0.56250    0.57500     0.5625    0.17500    0.38125   \n",
      "22    0.56250    0.57500    0.56250     0.1750    0.38125    0.43750   \n",
      "\n",
      "    var1(t+9)  var1(t+10)  var1(t+11)  \n",
      "18    0.56250     0.17500     0.38125  \n",
      "19    0.17500     0.38125     0.43750  \n",
      "20    0.38125     0.43750     0.40625  \n",
      "21    0.43750     0.40625     0.44375  \n",
      "22    0.40625     0.44375     0.43125  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "(78, 30)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = master_data2.iloc[:,1:]\n",
    "values = dataset.values\n",
    "print(values.shape)\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "#print(values)\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_lag, n_seq)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "# reframed.drop(reframed.iloc[:,25:], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    "print(reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 18, 1) (65, 12) (1, 18, 1) (1, 12)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "train = values[:-1, :]\n",
    "test = values[-1:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[12:, :-(n_seq)], train[12:, -(n_seq):]\n",
    "test_X, test_y = test[:, :-n_seq], test[:, -n_seq:]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], n_feature))\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_feature))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "h1=n_lag*2\n",
    "h2=n_lag*2\n",
    "h3=n_seq*2\n",
    "h4=n_seq\n",
    "drop1=0.3\n",
    "drop2=0.2\n",
    "drop3=0.1 \n",
    "drop4=0.1\n",
    "n_y=n_seq\n",
    "epoch=1000\n",
    "batch_size=8\n",
    "lr=0.001\n",
    "L1=0.00\n",
    "L2=0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(LSTM(h1, batch_input_shape=(batch_size,train_X.shape[1],train_X.shape[2]), stateful=True))#,return_sequences=True, recurrent_regularizer=reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "reg = L1L2(l1=L1, l2=L2)\n",
    "model.add(LSTM(h1, input_shape=(train_X.shape[1],train_X.shape[2]),return_sequences=True, recurrent_regularizer=reg))\n",
    "model.add(Dropout(drop1, seed = 1))\n",
    "model.add(LSTM(h2,return_sequences=True))\n",
    "model.add(Dropout(drop2, seed = 1))\n",
    "model.add(LSTM(h3,return_sequences=True))\n",
    "model.add(Dropout(drop3, seed = 1))\n",
    "model.add(LSTM(h4,return_sequences=False))\n",
    "model.add(Dropout(drop4, seed = 1))\n",
    "model.add(Dense(n_seq, activation='relu'))\n",
    "model.add(Dense(n_y, activation='relu'))\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mae', optimizer= adam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=load_model('LSTM_12_month.h5')\n",
    "# weights=model.get_weights()\n",
    "# print(weights)\n",
    "# model.save_weights('weights.hdf5')\n",
    "# model.set_weights(weights)\n",
    "# model.load_weights('weights.hdf5')\n",
    "# model.load_weights('weights_42371381890000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65 samples, validate on 1 samples\n",
      "Epoch 1/1000\n",
      " - 3s - loss: 2.1508 - val_loss: 1.8727\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1.8020 - val_loss: 1.5737\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 1.5141 - val_loss: 1.3158\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 1.2812 - val_loss: 1.1088\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 1.0831 - val_loss: 0.9370\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 0.9198 - val_loss: 0.7933\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.7838 - val_loss: 0.6753\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 0.6704 - val_loss: 0.5786\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 0.5775 - val_loss: 0.4950\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 0.4991 - val_loss: 0.4260\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 0.4326 - val_loss: 0.3664\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 0.3762 - val_loss: 0.3126\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 0.3283 - val_loss: 0.2708\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 0.2865 - val_loss: 0.2379\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 0.2563 - val_loss: 0.2091\n",
      "Epoch 16/1000\n",
      " - 1s - loss: 0.2257 - val_loss: 0.1846\n",
      "Epoch 17/1000\n",
      " - 1s - loss: 0.2039 - val_loss: 0.1645\n",
      "Epoch 18/1000\n",
      " - 1s - loss: 0.1846 - val_loss: 0.1497\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.1686 - val_loss: 0.1325\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.1575 - val_loss: 0.1218\n",
      "Epoch 21/1000\n",
      " - 1s - loss: 0.1413 - val_loss: 0.1095\n",
      "Epoch 22/1000\n",
      " - 1s - loss: 0.1326 - val_loss: 0.1019\n",
      "Epoch 23/1000\n",
      " - 1s - loss: 0.1244 - val_loss: 0.0923\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.1185 - val_loss: 0.0866\n",
      "Epoch 25/1000\n",
      " - 1s - loss: 0.1115 - val_loss: 0.0804\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 0.1063 - val_loss: 0.0777\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 0.1018 - val_loss: 0.0727\n",
      "Epoch 28/1000\n",
      " - 1s - loss: 0.0983 - val_loss: 0.0700\n",
      "Epoch 29/1000\n",
      " - 1s - loss: 0.0929 - val_loss: 0.0663\n",
      "Epoch 30/1000\n",
      " - 1s - loss: 0.0915 - val_loss: 0.0656\n",
      "Epoch 31/1000\n",
      " - 1s - loss: 0.0898 - val_loss: 0.0625\n",
      "Epoch 32/1000\n",
      " - 1s - loss: 0.0880 - val_loss: 0.0622\n",
      "Epoch 33/1000\n",
      " - 1s - loss: 0.0839 - val_loss: 0.0600\n",
      "Epoch 34/1000\n",
      " - 1s - loss: 0.0841 - val_loss: 0.0594\n",
      "Epoch 35/1000\n",
      " - 1s - loss: 0.0833 - val_loss: 0.0565\n",
      "Epoch 36/1000\n",
      " - 1s - loss: 0.0828 - val_loss: 0.0571\n",
      "Epoch 37/1000\n",
      " - 1s - loss: 0.0801 - val_loss: 0.0551\n",
      "Epoch 38/1000\n",
      " - 1s - loss: 0.0798 - val_loss: 0.0548\n",
      "Epoch 39/1000\n",
      " - 1s - loss: 0.0781 - val_loss: 0.0543\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 0.0785 - val_loss: 0.0537\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 0.0789 - val_loss: 0.0496\n",
      "Epoch 42/1000\n",
      " - 1s - loss: 0.0801 - val_loss: 0.0542\n",
      "Epoch 43/1000\n",
      " - 1s - loss: 0.0772 - val_loss: 0.0499\n",
      "Epoch 44/1000\n",
      " - 1s - loss: 0.0762 - val_loss: 0.0503\n",
      "Epoch 45/1000\n",
      " - 1s - loss: 0.0764 - val_loss: 0.0503\n",
      "Epoch 46/1000\n",
      " - 1s - loss: 0.0773 - val_loss: 0.0519\n",
      "Epoch 47/1000\n",
      " - 1s - loss: 0.0771 - val_loss: 0.0502\n",
      "Epoch 48/1000\n",
      " - 1s - loss: 0.0775 - val_loss: 0.0504\n",
      "Epoch 49/1000\n",
      " - 1s - loss: 0.0760 - val_loss: 0.0479\n",
      "Epoch 50/1000\n",
      " - 1s - loss: 0.0779 - val_loss: 0.0511\n",
      "Epoch 51/1000\n",
      " - 1s - loss: 0.0756 - val_loss: 0.0506\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 0.0764 - val_loss: 0.0504\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 0.0753 - val_loss: 0.0495\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 0.0761 - val_loss: 0.0513\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 0.0765 - val_loss: 0.0482\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 0.0771 - val_loss: 0.0508\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 0.0763 - val_loss: 0.0502\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.0756 - val_loss: 0.0506\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 0.0746 - val_loss: 0.0497\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 0.0754 - val_loss: 0.0487\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 0.0751 - val_loss: 0.0490\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.0744 - val_loss: 0.0508\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.0756 - val_loss: 0.0502\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.0764 - val_loss: 0.0514\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.0749 - val_loss: 0.0496\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.0767 - val_loss: 0.0513\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.0752 - val_loss: 0.0502\n",
      "Epoch 68/1000\n",
      " - 1s - loss: 0.0744 - val_loss: 0.0511\n",
      "Epoch 69/1000\n",
      " - 1s - loss: 0.0750 - val_loss: 0.0501\n",
      "Epoch 70/1000\n",
      " - 1s - loss: 0.0756 - val_loss: 0.0510\n",
      "Epoch 71/1000\n",
      " - 1s - loss: 0.0760 - val_loss: 0.0479\n",
      "Epoch 72/1000\n",
      " - 1s - loss: 0.0764 - val_loss: 0.0459\n",
      "Epoch 73/1000\n",
      " - 1s - loss: 0.0718 - val_loss: 0.0412\n",
      "Epoch 74/1000\n",
      " - 1s - loss: 0.0724 - val_loss: 0.0439\n",
      "Epoch 75/1000\n",
      " - 1s - loss: 0.0713 - val_loss: 0.0408\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.0666 - val_loss: 0.0441\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.0657 - val_loss: 0.0468\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.0653 - val_loss: 0.0475\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.0649 - val_loss: 0.0482\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.0638 - val_loss: 0.0482\n",
      "Epoch 81/1000\n",
      " - 1s - loss: 0.0627 - val_loss: 0.0480\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.0633 - val_loss: 0.0475\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.0623 - val_loss: 0.0471\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.0633 - val_loss: 0.0476\n",
      "Epoch 85/1000\n",
      " - 1s - loss: 0.0622 - val_loss: 0.0488\n",
      "Epoch 86/1000\n",
      " - 1s - loss: 0.0614 - val_loss: 0.0497\n",
      "Epoch 87/1000\n",
      " - 1s - loss: 0.0609 - val_loss: 0.0503\n",
      "Epoch 88/1000\n",
      " - 1s - loss: 0.0617 - val_loss: 0.0504\n",
      "Epoch 89/1000\n",
      " - 1s - loss: 0.0602 - val_loss: 0.0501\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.0587 - val_loss: 0.0501\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.0604 - val_loss: 0.0502\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.0599 - val_loss: 0.0493\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.0631 - val_loss: 0.0491\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.0573 - val_loss: 0.0490\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0487\n",
      "Epoch 96/1000\n",
      " - 1s - loss: 0.0598 - val_loss: 0.0485\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.0578 - val_loss: 0.0470\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.0591 - val_loss: 0.0477\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0468\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.0583 - val_loss: 0.0465\n",
      "Epoch 101/1000\n",
      " - 1s - loss: 0.0582 - val_loss: 0.0465\n",
      "Epoch 102/1000\n",
      " - 1s - loss: 0.0585 - val_loss: 0.0475\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.0590 - val_loss: 0.0457\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.0589 - val_loss: 0.0476\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0469\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.0592 - val_loss: 0.0481\n",
      "Epoch 107/1000\n",
      " - 1s - loss: 0.0577 - val_loss: 0.0458\n",
      "Epoch 108/1000\n",
      " - 1s - loss: 0.0581 - val_loss: 0.0452\n",
      "Epoch 109/1000\n",
      " - 1s - loss: 0.0610 - val_loss: 0.0474\n",
      "Epoch 110/1000\n",
      " - 1s - loss: 0.0572 - val_loss: 0.0455\n",
      "Epoch 111/1000\n",
      " - 1s - loss: 0.0579 - val_loss: 0.0467\n",
      "Epoch 112/1000\n",
      " - 1s - loss: 0.0584 - val_loss: 0.0457\n",
      "Epoch 113/1000\n",
      " - 1s - loss: 0.0607 - val_loss: 0.0481\n",
      "Epoch 114/1000\n",
      " - 1s - loss: 0.0570 - val_loss: 0.0452\n",
      "Epoch 115/1000\n",
      " - 1s - loss: 0.0588 - val_loss: 0.0445\n",
      "Epoch 116/1000\n",
      " - 1s - loss: 0.0581 - val_loss: 0.0454\n",
      "Epoch 117/1000\n",
      " - 1s - loss: 0.0582 - val_loss: 0.0450\n",
      "Epoch 118/1000\n",
      " - 1s - loss: 0.0583 - val_loss: 0.0461\n",
      "Epoch 119/1000\n",
      " - 1s - loss: 0.0571 - val_loss: 0.0453\n",
      "Epoch 120/1000\n",
      " - 1s - loss: 0.0584 - val_loss: 0.0469\n",
      "Epoch 121/1000\n",
      " - 1s - loss: 0.0573 - val_loss: 0.0462\n",
      "Epoch 122/1000\n",
      " - 1s - loss: 0.0582 - val_loss: 0.0470\n",
      "Epoch 123/1000\n",
      " - 1s - loss: 0.0565 - val_loss: 0.0453\n",
      "Epoch 124/1000\n",
      " - 1s - loss: 0.0571 - val_loss: 0.0449\n",
      "Epoch 125/1000\n",
      " - 1s - loss: 0.0570 - val_loss: 0.0454\n",
      "Epoch 126/1000\n",
      " - 1s - loss: 0.0574 - val_loss: 0.0454\n",
      "Epoch 127/1000\n",
      " - 1s - loss: 0.0575 - val_loss: 0.0455\n",
      "Epoch 128/1000\n",
      " - 1s - loss: 0.0565 - val_loss: 0.0459\n",
      "Epoch 129/1000\n",
      " - 1s - loss: 0.0570 - val_loss: 0.0462\n",
      "Epoch 130/1000\n",
      " - 1s - loss: 0.0582 - val_loss: 0.0461\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0455\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.0579 - val_loss: 0.0464\n",
      "Epoch 133/1000\n",
      " - 1s - loss: 0.0585 - val_loss: 0.0457\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.0608 - val_loss: 0.0464\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0464\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0458\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.0603 - val_loss: 0.0462\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0457\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0458\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.0576 - val_loss: 0.0465\n",
      "Epoch 141/1000\n",
      " - 1s - loss: 0.0576 - val_loss: 0.0473\n",
      "Epoch 142/1000\n",
      " - 1s - loss: 0.0575 - val_loss: 0.0471\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.0586 - val_loss: 0.0468\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0465\n",
      "Epoch 145/1000\n",
      " - 1s - loss: 0.0568 - val_loss: 0.0467\n",
      "Epoch 146/1000\n",
      " - 1s - loss: 0.0568 - val_loss: 0.0461\n",
      "Epoch 147/1000\n",
      " - 1s - loss: 0.0572 - val_loss: 0.0458\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.0577 - val_loss: 0.0453\n",
      "Epoch 149/1000\n",
      " - 1s - loss: 0.0563 - val_loss: 0.0456\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0456\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0581 - val_loss: 0.0464\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.0581 - val_loss: 0.0449\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.0585 - val_loss: 0.0454\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0462\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0458\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.0572 - val_loss: 0.0456\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0462\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0456\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0451\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0447\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.0585 - val_loss: 0.0456\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0455\n",
      "Epoch 163/1000\n",
      " - 0s - loss: 0.0586 - val_loss: 0.0466\n",
      "Epoch 164/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0449\n",
      "Epoch 165/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0449\n",
      "Epoch 166/1000\n",
      " - 0s - loss: 0.0573 - val_loss: 0.0457\n",
      "Epoch 167/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0457\n",
      "Epoch 168/1000\n",
      " - 1s - loss: 0.0563 - val_loss: 0.0460\n",
      "Epoch 169/1000\n",
      " - 1s - loss: 0.0572 - val_loss: 0.0452\n",
      "Epoch 170/1000\n",
      " - 1s - loss: 0.0599 - val_loss: 0.0458\n",
      "Epoch 171/1000\n",
      " - 1s - loss: 0.0563 - val_loss: 0.0447\n",
      "Epoch 172/1000\n",
      " - 1s - loss: 0.0573 - val_loss: 0.0449\n",
      "Epoch 173/1000\n",
      " - 1s - loss: 0.0580 - val_loss: 0.0448\n",
      "Epoch 174/1000\n",
      " - 1s - loss: 0.0572 - val_loss: 0.0453\n",
      "Epoch 175/1000\n",
      " - 0s - loss: 0.0581 - val_loss: 0.0455\n",
      "Epoch 176/1000\n",
      " - 0s - loss: 0.0603 - val_loss: 0.0477\n",
      "Epoch 177/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0465\n",
      "Epoch 178/1000\n",
      " - 0s - loss: 0.0577 - val_loss: 0.0461\n",
      "Epoch 179/1000\n",
      " - 0s - loss: 0.0583 - val_loss: 0.0466\n",
      "Epoch 180/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0454\n",
      "Epoch 181/1000\n",
      " - 0s - loss: 0.0580 - val_loss: 0.0450\n",
      "Epoch 182/1000\n",
      " - 1s - loss: 0.0566 - val_loss: 0.0447\n",
      "Epoch 183/1000\n",
      " - 1s - loss: 0.0572 - val_loss: 0.0460\n",
      "Epoch 184/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0462\n",
      "Epoch 185/1000\n",
      " - 1s - loss: 0.0584 - val_loss: 0.0465\n",
      "Epoch 186/1000\n",
      " - 1s - loss: 0.0569 - val_loss: 0.0456\n",
      "Epoch 187/1000\n",
      " - 1s - loss: 0.0565 - val_loss: 0.0453\n",
      "Epoch 188/1000\n",
      " - 1s - loss: 0.0577 - val_loss: 0.0458\n",
      "Epoch 189/1000\n",
      " - 1s - loss: 0.0570 - val_loss: 0.0452\n",
      "Epoch 190/1000\n",
      " - 1s - loss: 0.0573 - val_loss: 0.0453\n",
      "Epoch 191/1000\n",
      " - 1s - loss: 0.0563 - val_loss: 0.0441\n",
      "Epoch 192/1000\n",
      " - 1s - loss: 0.0571 - val_loss: 0.0449\n",
      "Epoch 193/1000\n",
      " - 1s - loss: 0.0564 - val_loss: 0.0451\n",
      "Epoch 194/1000\n",
      " - 1s - loss: 0.0583 - val_loss: 0.0455\n",
      "Epoch 195/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0454\n",
      "Epoch 196/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0458\n",
      "Epoch 197/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0456\n",
      "Epoch 198/1000\n",
      " - 0s - loss: 0.0571 - val_loss: 0.0461\n",
      "Epoch 199/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0457\n",
      "Epoch 200/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0460\n",
      "Epoch 201/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0454\n",
      "Epoch 202/1000\n",
      " - 1s - loss: 0.0568 - val_loss: 0.0459\n",
      "Epoch 203/1000\n",
      " - 1s - loss: 0.0565 - val_loss: 0.0455\n",
      "Epoch 204/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0468\n",
      "Epoch 205/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0454\n",
      "Epoch 206/1000\n",
      " - 1s - loss: 0.0574 - val_loss: 0.0449\n",
      "Epoch 207/1000\n",
      " - 1s - loss: 0.0575 - val_loss: 0.0451\n",
      "Epoch 208/1000\n",
      " - 1s - loss: 0.0588 - val_loss: 0.0460\n",
      "Epoch 209/1000\n",
      " - 1s - loss: 0.0574 - val_loss: 0.0461\n",
      "Epoch 210/1000\n",
      " - 0s - loss: 0.0582 - val_loss: 0.0449\n",
      "Epoch 211/1000\n",
      " - 0s - loss: 0.0599 - val_loss: 0.0483\n",
      "Epoch 212/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0459\n",
      "Epoch 213/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0447\n",
      "Epoch 214/1000\n",
      " - 0s - loss: 0.0581 - val_loss: 0.0459\n",
      "Epoch 215/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0458\n",
      "Epoch 216/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0468\n",
      "Epoch 217/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0467\n",
      "Epoch 218/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0460\n",
      "Epoch 219/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0464\n",
      "Epoch 220/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0465\n",
      "Epoch 221/1000\n",
      " - 0s - loss: 0.0573 - val_loss: 0.0463\n",
      "Epoch 222/1000\n",
      " - 0s - loss: 0.0583 - val_loss: 0.0462\n",
      "Epoch 223/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0451\n",
      "Epoch 224/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0453\n",
      "Epoch 225/1000\n",
      " - 0s - loss: 0.0572 - val_loss: 0.0461\n",
      "Epoch 226/1000\n",
      " - 0s - loss: 0.0577 - val_loss: 0.0465\n",
      "Epoch 227/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0463\n",
      "Epoch 228/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0467\n",
      "Epoch 229/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0456\n",
      "Epoch 230/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0462\n",
      "Epoch 231/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0463\n",
      "Epoch 232/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0455\n",
      "Epoch 233/1000\n",
      " - 0s - loss: 0.0577 - val_loss: 0.0451\n",
      "Epoch 234/1000\n",
      " - 0s - loss: 0.0580 - val_loss: 0.0448\n",
      "Epoch 235/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0461\n",
      "Epoch 236/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0456\n",
      "Epoch 237/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0468\n",
      "Epoch 238/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0463\n",
      "Epoch 239/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0452\n",
      "Epoch 240/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0453\n",
      "Epoch 241/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0462\n",
      "Epoch 242/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0452\n",
      "Epoch 243/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0465\n",
      "Epoch 244/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0455\n",
      "Epoch 245/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0461\n",
      "Epoch 246/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0454\n",
      "Epoch 247/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0463\n",
      "Epoch 248/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0445\n",
      "Epoch 249/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0456\n",
      "Epoch 250/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0455\n",
      "Epoch 251/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0463\n",
      "Epoch 252/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0455\n",
      "Epoch 253/1000\n",
      " - 0s - loss: 0.0583 - val_loss: 0.0477\n",
      "Epoch 254/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0460\n",
      "Epoch 255/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0460\n",
      "Epoch 256/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0459\n",
      "Epoch 257/1000\n",
      " - 0s - loss: 0.0572 - val_loss: 0.0460\n",
      "Epoch 258/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0452\n",
      "Epoch 259/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0457\n",
      "Epoch 260/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0447\n",
      "Epoch 261/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0458\n",
      "Epoch 262/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0449\n",
      "Epoch 263/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0456\n",
      "Epoch 264/1000\n",
      " - 0s - loss: 0.0577 - val_loss: 0.0462\n",
      "Epoch 265/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0464\n",
      "Epoch 266/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0464\n",
      "Epoch 267/1000\n",
      " - 0s - loss: 0.0580 - val_loss: 0.0457\n",
      "Epoch 268/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0439\n",
      "Epoch 269/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0449\n",
      "Epoch 270/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0459\n",
      "Epoch 271/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0456\n",
      "Epoch 272/1000\n",
      " - 0s - loss: 0.0579 - val_loss: 0.0465\n",
      "Epoch 273/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0440\n",
      "Epoch 274/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0454\n",
      "Epoch 275/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0459\n",
      "Epoch 276/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0469\n",
      "Epoch 277/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0475\n",
      "Epoch 278/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0460\n",
      "Epoch 279/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0445\n",
      "Epoch 280/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0456\n",
      "Epoch 281/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0462\n",
      "Epoch 282/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0453\n",
      "Epoch 283/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0442\n",
      "Epoch 284/1000\n",
      " - 0s - loss: 0.0580 - val_loss: 0.0455\n",
      "Epoch 285/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0456\n",
      "Epoch 286/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0457\n",
      "Epoch 287/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0458\n",
      "Epoch 288/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0463\n",
      "Epoch 289/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0462\n",
      "Epoch 290/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0455\n",
      "Epoch 291/1000\n",
      " - 0s - loss: 0.0586 - val_loss: 0.0459\n",
      "Epoch 292/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0462\n",
      "Epoch 293/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0452\n",
      "Epoch 294/1000\n",
      " - 0s - loss: 0.0583 - val_loss: 0.0463\n",
      "Epoch 295/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0456\n",
      "Epoch 296/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0442\n",
      "Epoch 297/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0444\n",
      "Epoch 298/1000\n",
      " - 0s - loss: 0.0573 - val_loss: 0.0449\n",
      "Epoch 299/1000\n",
      " - 0s - loss: 0.0583 - val_loss: 0.0466\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0561 - val_loss: 0.0454\n",
      "Epoch 301/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0455\n",
      "Epoch 302/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0459\n",
      "Epoch 303/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0449\n",
      "Epoch 304/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0453\n",
      "Epoch 305/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0442\n",
      "Epoch 306/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0451\n",
      "Epoch 307/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0448\n",
      "Epoch 308/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0453\n",
      "Epoch 309/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0452\n",
      "Epoch 310/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0449\n",
      "Epoch 311/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0451\n",
      "Epoch 312/1000\n",
      " - 0s - loss: 0.0604 - val_loss: 0.0464\n",
      "Epoch 313/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0453\n",
      "Epoch 314/1000\n",
      " - 0s - loss: 0.0585 - val_loss: 0.0449\n",
      "Epoch 315/1000\n",
      " - 0s - loss: 0.0579 - val_loss: 0.0457\n",
      "Epoch 316/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0456\n",
      "Epoch 317/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0453\n",
      "Epoch 318/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0457\n",
      "Epoch 319/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0458\n",
      "Epoch 320/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0457\n",
      "Epoch 321/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0457\n",
      "Epoch 322/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0462\n",
      "Epoch 323/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0462\n",
      "Epoch 324/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0455\n",
      "Epoch 325/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0467\n",
      "Epoch 326/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0458\n",
      "Epoch 327/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0456\n",
      "Epoch 328/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0445\n",
      "Epoch 329/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0455\n",
      "Epoch 330/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0448\n",
      "Epoch 331/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0452\n",
      "Epoch 332/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0456\n",
      "Epoch 333/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0441\n",
      "Epoch 334/1000\n",
      " - 0s - loss: 0.0578 - val_loss: 0.0447\n",
      "Epoch 335/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0457\n",
      "Epoch 336/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0463\n",
      "Epoch 337/1000\n",
      " - 0s - loss: 0.0573 - val_loss: 0.0455\n",
      "Epoch 338/1000\n",
      " - 0s - loss: 0.0582 - val_loss: 0.0468\n",
      "Epoch 339/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0462\n",
      "Epoch 340/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0451\n",
      "Epoch 341/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0463\n",
      "Epoch 342/1000\n",
      " - 0s - loss: 0.0553 - val_loss: 0.0454\n",
      "Epoch 343/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0450\n",
      "Epoch 344/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0448\n",
      "Epoch 345/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0449\n",
      "Epoch 346/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0452\n",
      "Epoch 347/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0466\n",
      "Epoch 348/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0462\n",
      "Epoch 349/1000\n",
      " - 0s - loss: 0.0593 - val_loss: 0.0460\n",
      "Epoch 350/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0462\n",
      "Epoch 351/1000\n",
      " - 0s - loss: 0.0582 - val_loss: 0.0459\n",
      "Epoch 352/1000\n",
      " - 0s - loss: 0.0595 - val_loss: 0.0458\n",
      "Epoch 353/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0455\n",
      "Epoch 354/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0449\n",
      "Epoch 355/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0459\n",
      "Epoch 356/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0460\n",
      "Epoch 357/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0460\n",
      "Epoch 358/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0465\n",
      "Epoch 359/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0463\n",
      "Epoch 360/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0464\n",
      "Epoch 361/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0467\n",
      "Epoch 362/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0458\n",
      "Epoch 363/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0463\n",
      "Epoch 364/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0465\n",
      "Epoch 365/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0470\n",
      "Epoch 366/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0476\n",
      "Epoch 367/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0476\n",
      "Epoch 368/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0465\n",
      "Epoch 369/1000\n",
      " - 0s - loss: 0.0572 - val_loss: 0.0473\n",
      "Epoch 370/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0469\n",
      "Epoch 371/1000\n",
      " - 0s - loss: 0.0573 - val_loss: 0.0465\n",
      "Epoch 372/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0453\n",
      "Epoch 373/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0451\n",
      "Epoch 374/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0449\n",
      "Epoch 375/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0450\n",
      "Epoch 376/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0457\n",
      "Epoch 377/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0458\n",
      "Epoch 378/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0460\n",
      "Epoch 379/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0463\n",
      "Epoch 380/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0458\n",
      "Epoch 381/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0448\n",
      "Epoch 382/1000\n",
      " - 0s - loss: 0.0571 - val_loss: 0.0453\n",
      "Epoch 383/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0465\n",
      "Epoch 384/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0472\n",
      "Epoch 385/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0459\n",
      "Epoch 386/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0460\n",
      "Epoch 387/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0446\n",
      "Epoch 388/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0458\n",
      "Epoch 389/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0454\n",
      "Epoch 390/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0453\n",
      "Epoch 391/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0452\n",
      "Epoch 392/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0459\n",
      "Epoch 393/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0457\n",
      "Epoch 394/1000\n",
      " - 0s - loss: 0.0579 - val_loss: 0.0468\n",
      "Epoch 395/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0469\n",
      "Epoch 396/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0458\n",
      "Epoch 397/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0462\n",
      "Epoch 398/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0468\n",
      "Epoch 399/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0469\n",
      "Epoch 400/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0457\n",
      "Epoch 401/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0460\n",
      "Epoch 402/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0459\n",
      "Epoch 403/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0446\n",
      "Epoch 404/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0449\n",
      "Epoch 405/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0464\n",
      "Epoch 406/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0458\n",
      "Epoch 407/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0451\n",
      "Epoch 408/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0468\n",
      "Epoch 409/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0451\n",
      "Epoch 410/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0444\n",
      "Epoch 411/1000\n",
      " - 0s - loss: 0.0571 - val_loss: 0.0446\n",
      "Epoch 412/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0438\n",
      "Epoch 413/1000\n",
      " - 0s - loss: 0.0575 - val_loss: 0.0446\n",
      "Epoch 414/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0443\n",
      "Epoch 415/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0456\n",
      "Epoch 416/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0459\n",
      "Epoch 417/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0462\n",
      "Epoch 418/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0448\n",
      "Epoch 419/1000\n",
      " - 0s - loss: 0.0573 - val_loss: 0.0444\n",
      "Epoch 420/1000\n",
      " - 0s - loss: 0.0571 - val_loss: 0.0453\n",
      "Epoch 421/1000\n",
      " - 0s - loss: 0.0571 - val_loss: 0.0459\n",
      "Epoch 422/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0455\n",
      "Epoch 423/1000\n",
      " - 1s - loss: 0.0559 - val_loss: 0.0464\n",
      "Epoch 424/1000\n",
      " - 1s - loss: 0.0560 - val_loss: 0.0461\n",
      "Epoch 425/1000\n",
      " - 1s - loss: 0.0561 - val_loss: 0.0451\n",
      "Epoch 426/1000\n",
      " - 1s - loss: 0.0576 - val_loss: 0.0466\n",
      "Epoch 427/1000\n",
      " - 1s - loss: 0.0572 - val_loss: 0.0469\n",
      "Epoch 428/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0456\n",
      "Epoch 429/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0463\n",
      "Epoch 430/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0462\n",
      "Epoch 431/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0454\n",
      "Epoch 432/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0447\n",
      "Epoch 433/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0455\n",
      "Epoch 434/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0456\n",
      "Epoch 435/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0456\n",
      "Epoch 436/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0452\n",
      "Epoch 437/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0451\n",
      "Epoch 438/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0454\n",
      "Epoch 439/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0458\n",
      "Epoch 440/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0457\n",
      "Epoch 441/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0460\n",
      "Epoch 442/1000\n",
      " - 0s - loss: 0.0551 - val_loss: 0.0466\n",
      "Epoch 443/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0460\n",
      "Epoch 444/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0461\n",
      "Epoch 445/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0449\n",
      "Epoch 446/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0453\n",
      "Epoch 447/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0453\n",
      "Epoch 448/1000\n",
      " - 0s - loss: 0.0572 - val_loss: 0.0463\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0567 - val_loss: 0.0458\n",
      "Epoch 450/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0458\n",
      "Epoch 451/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0456\n",
      "Epoch 452/1000\n",
      " - 0s - loss: 0.0571 - val_loss: 0.0454\n",
      "Epoch 453/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0460\n",
      "Epoch 454/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0456\n",
      "Epoch 455/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0455\n",
      "Epoch 456/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0453\n",
      "Epoch 457/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0464\n",
      "Epoch 458/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0457\n",
      "Epoch 459/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0449\n",
      "Epoch 460/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0452\n",
      "Epoch 461/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0455\n",
      "Epoch 462/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0449\n",
      "Epoch 463/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0452\n",
      "Epoch 464/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0446\n",
      "Epoch 465/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0450\n",
      "Epoch 466/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0456\n",
      "Epoch 467/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0454\n",
      "Epoch 468/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0450\n",
      "Epoch 469/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0459\n",
      "Epoch 470/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0452\n",
      "Epoch 471/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0449\n",
      "Epoch 472/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0464\n",
      "Epoch 473/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0473\n",
      "Epoch 474/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0450\n",
      "Epoch 475/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0459\n",
      "Epoch 476/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0450\n",
      "Epoch 477/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0451\n",
      "Epoch 478/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0451\n",
      "Epoch 479/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0459\n",
      "Epoch 480/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0442\n",
      "Epoch 481/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0442\n",
      "Epoch 482/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0450\n",
      "Epoch 483/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0450\n",
      "Epoch 484/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0462\n",
      "Epoch 485/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0459\n",
      "Epoch 486/1000\n",
      " - 0s - loss: 0.0595 - val_loss: 0.0466\n",
      "Epoch 487/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0458\n",
      "Epoch 488/1000\n",
      " - 0s - loss: 0.0571 - val_loss: 0.0454\n",
      "Epoch 489/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0454\n",
      "Epoch 490/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0458\n",
      "Epoch 491/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0461\n",
      "Epoch 492/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0462\n",
      "Epoch 493/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0465\n",
      "Epoch 494/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0465\n",
      "Epoch 495/1000\n",
      " - 0s - loss: 0.0573 - val_loss: 0.0468\n",
      "Epoch 496/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0467\n",
      "Epoch 497/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0464\n",
      "Epoch 498/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0464\n",
      "Epoch 499/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0465\n",
      "Epoch 500/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0465\n",
      "Epoch 501/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0461\n",
      "Epoch 502/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0460\n",
      "Epoch 503/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0454\n",
      "Epoch 504/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0452\n",
      "Epoch 505/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0462\n",
      "Epoch 506/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0456\n",
      "Epoch 507/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0461\n",
      "Epoch 508/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0456\n",
      "Epoch 509/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0449\n",
      "Epoch 510/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0455\n",
      "Epoch 511/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0450\n",
      "Epoch 512/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0441\n",
      "Epoch 513/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0444\n",
      "Epoch 514/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0457\n",
      "Epoch 515/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0466\n",
      "Epoch 516/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0460\n",
      "Epoch 517/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0461\n",
      "Epoch 518/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0464\n",
      "Epoch 519/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0463\n",
      "Epoch 520/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0460\n",
      "Epoch 521/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0460\n",
      "Epoch 522/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0451\n",
      "Epoch 523/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0457\n",
      "Epoch 524/1000\n",
      " - 0s - loss: 0.0571 - val_loss: 0.0462\n",
      "Epoch 525/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0458\n",
      "Epoch 526/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0463\n",
      "Epoch 527/1000\n",
      " - 1s - loss: 0.0556 - val_loss: 0.0466\n",
      "Epoch 528/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0461\n",
      "Epoch 529/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0457\n",
      "Epoch 530/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0455\n",
      "Epoch 531/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0459\n",
      "Epoch 532/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0457\n",
      "Epoch 533/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0450\n",
      "Epoch 534/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0453\n",
      "Epoch 535/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0460\n",
      "Epoch 536/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0459\n",
      "Epoch 537/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0463\n",
      "Epoch 538/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0449\n",
      "Epoch 539/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0444\n",
      "Epoch 540/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0451\n",
      "Epoch 541/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0452\n",
      "Epoch 542/1000\n",
      " - 0s - loss: 0.0569 - val_loss: 0.0472\n",
      "Epoch 543/1000\n",
      " - 0s - loss: 0.0568 - val_loss: 0.0451\n",
      "Epoch 544/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0448\n",
      "Epoch 545/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0447\n",
      "Epoch 546/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0453\n",
      "Epoch 547/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0456\n",
      "Epoch 548/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0465\n",
      "Epoch 549/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0463\n",
      "Epoch 550/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0445\n",
      "Epoch 551/1000\n",
      " - 0s - loss: 0.0574 - val_loss: 0.0455\n",
      "Epoch 552/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0454\n",
      "Epoch 553/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0455\n",
      "Epoch 554/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0453\n",
      "Epoch 555/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0449\n",
      "Epoch 556/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0458\n",
      "Epoch 557/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0459\n",
      "Epoch 558/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0448\n",
      "Epoch 559/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0450\n",
      "Epoch 560/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0456\n",
      "Epoch 561/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0458\n",
      "Epoch 562/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0462\n",
      "Epoch 563/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0458\n",
      "Epoch 564/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0463\n",
      "Epoch 565/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0465\n",
      "Epoch 566/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0453\n",
      "Epoch 567/1000\n",
      " - 0s - loss: 0.0582 - val_loss: 0.0453\n",
      "Epoch 568/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0457\n",
      "Epoch 569/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0469\n",
      "Epoch 570/1000\n",
      " - 0s - loss: 0.0551 - val_loss: 0.0473\n",
      "Epoch 571/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0462\n",
      "Epoch 572/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0456\n",
      "Epoch 573/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0453\n",
      "Epoch 574/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0458\n",
      "Epoch 575/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0454\n",
      "Epoch 576/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0451\n",
      "Epoch 577/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0456\n",
      "Epoch 578/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0464\n",
      "Epoch 579/1000\n",
      " - 0s - loss: 0.0563 - val_loss: 0.0462\n",
      "Epoch 580/1000\n",
      " - 0s - loss: 0.0579 - val_loss: 0.0459\n",
      "Epoch 581/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0460\n",
      "Epoch 582/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0465\n",
      "Epoch 583/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0463\n",
      "Epoch 584/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0445\n",
      "Epoch 585/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0447\n",
      "Epoch 586/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0459\n",
      "Epoch 587/1000\n",
      " - 0s - loss: 0.0552 - val_loss: 0.0459\n",
      "Epoch 588/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0460\n",
      "Epoch 589/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0466\n",
      "Epoch 590/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0466\n",
      "Epoch 591/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0464\n",
      "Epoch 592/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0453\n",
      "Epoch 593/1000\n",
      " - 0s - loss: 0.0552 - val_loss: 0.0454\n",
      "Epoch 594/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0459\n",
      "Epoch 595/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0470\n",
      "Epoch 596/1000\n",
      " - 0s - loss: 0.0552 - val_loss: 0.0457\n",
      "Epoch 597/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0449\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0556 - val_loss: 0.0462\n",
      "Epoch 599/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0443\n",
      "Epoch 600/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.0432\n",
      "Epoch 601/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0430\n",
      "Epoch 602/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0436\n",
      "Epoch 603/1000\n",
      " - 0s - loss: 0.0550 - val_loss: 0.0442\n",
      "Epoch 604/1000\n",
      " - 0s - loss: 0.0553 - val_loss: 0.0442\n",
      "Epoch 605/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0450\n",
      "Epoch 606/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0447\n",
      "Epoch 607/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0433\n",
      "Epoch 608/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0428\n",
      "Epoch 609/1000\n",
      " - 0s - loss: 0.0553 - val_loss: 0.0431\n",
      "Epoch 610/1000\n",
      " - 0s - loss: 0.0549 - val_loss: 0.0449\n",
      "Epoch 611/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0447\n",
      "Epoch 612/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0438\n",
      "Epoch 613/1000\n",
      " - 0s - loss: 0.0550 - val_loss: 0.0443\n",
      "Epoch 614/1000\n",
      " - 0s - loss: 0.0549 - val_loss: 0.0433\n",
      "Epoch 615/1000\n",
      " - 0s - loss: 0.0552 - val_loss: 0.0435\n",
      "Epoch 616/1000\n",
      " - 0s - loss: 0.0552 - val_loss: 0.0430\n",
      "Epoch 617/1000\n",
      " - 0s - loss: 0.0553 - val_loss: 0.0425\n",
      "Epoch 618/1000\n",
      " - 0s - loss: 0.0560 - val_loss: 0.0428\n",
      "Epoch 619/1000\n",
      " - 0s - loss: 0.0552 - val_loss: 0.0433\n",
      "Epoch 620/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0442\n",
      "Epoch 621/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0433\n",
      "Epoch 622/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0436\n",
      "Epoch 623/1000\n",
      " - 0s - loss: 0.0553 - val_loss: 0.0440\n",
      "Epoch 624/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0433\n",
      "Epoch 625/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0426\n",
      "Epoch 626/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0429\n",
      "Epoch 627/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0430\n",
      "Epoch 628/1000\n",
      " - 0s - loss: 0.0572 - val_loss: 0.0424\n",
      "Epoch 629/1000\n",
      " - 0s - loss: 0.0553 - val_loss: 0.0426\n",
      "Epoch 630/1000\n",
      " - 0s - loss: 0.0548 - val_loss: 0.0425\n",
      "Epoch 631/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0432\n",
      "Epoch 632/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0429\n",
      "Epoch 633/1000\n",
      " - 0s - loss: 0.0550 - val_loss: 0.0418\n",
      "Epoch 634/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.0422\n",
      "Epoch 635/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0431\n",
      "Epoch 636/1000\n",
      " - 0s - loss: 0.0562 - val_loss: 0.0438\n",
      "Epoch 637/1000\n",
      " - 0s - loss: 0.0557 - val_loss: 0.0430\n",
      "Epoch 638/1000\n",
      " - 0s - loss: 0.0552 - val_loss: 0.0436\n",
      "Epoch 639/1000\n",
      " - 0s - loss: 0.0566 - val_loss: 0.0440\n",
      "Epoch 640/1000\n",
      " - 0s - loss: 0.0570 - val_loss: 0.0441\n",
      "Epoch 641/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.0434\n",
      "Epoch 642/1000\n",
      " - 0s - loss: 0.0559 - val_loss: 0.0426\n",
      "Epoch 643/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0432\n",
      "Epoch 644/1000\n",
      " - 0s - loss: 0.0553 - val_loss: 0.0437\n",
      "Epoch 645/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0433\n",
      "Epoch 646/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0430\n",
      "Epoch 647/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0428\n",
      "Epoch 648/1000\n",
      " - 0s - loss: 0.0545 - val_loss: 0.0423\n",
      "Epoch 649/1000\n",
      " - 0s - loss: 0.0545 - val_loss: 0.0422\n",
      "Epoch 650/1000\n",
      " - 0s - loss: 0.0553 - val_loss: 0.0425\n",
      "Epoch 651/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0428\n",
      "Epoch 652/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0460\n",
      "Epoch 653/1000\n",
      " - 0s - loss: 0.0552 - val_loss: 0.0439\n",
      "Epoch 654/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0409\n",
      "Epoch 655/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0411\n",
      "Epoch 656/1000\n",
      " - 0s - loss: 0.0550 - val_loss: 0.0419\n",
      "Epoch 657/1000\n",
      " - 0s - loss: 0.0546 - val_loss: 0.0428\n",
      "Epoch 658/1000\n",
      " - 0s - loss: 0.0558 - val_loss: 0.0425\n",
      "Epoch 659/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0417\n",
      "Epoch 660/1000\n",
      " - 0s - loss: 0.0546 - val_loss: 0.0422\n",
      "Epoch 661/1000\n",
      " - 0s - loss: 0.0548 - val_loss: 0.0421\n",
      "Epoch 662/1000\n",
      " - 0s - loss: 0.0550 - val_loss: 0.0426\n",
      "Epoch 663/1000\n",
      " - 0s - loss: 0.0543 - val_loss: 0.0428\n",
      "Epoch 664/1000\n",
      " - 0s - loss: 0.0546 - val_loss: 0.0433\n",
      "Epoch 665/1000\n",
      " - 0s - loss: 0.0549 - val_loss: 0.0432\n",
      "Epoch 666/1000\n",
      " - 0s - loss: 0.0540 - val_loss: 0.0433\n",
      "Epoch 667/1000\n",
      " - 0s - loss: 0.0550 - val_loss: 0.0431\n",
      "Epoch 668/1000\n",
      " - 0s - loss: 0.0538 - val_loss: 0.0437\n",
      "Epoch 669/1000\n",
      " - 0s - loss: 0.0551 - val_loss: 0.0430\n",
      "Epoch 670/1000\n",
      " - 0s - loss: 0.0551 - val_loss: 0.0430\n",
      "Epoch 671/1000\n",
      " - 0s - loss: 0.0548 - val_loss: 0.0427\n",
      "Epoch 672/1000\n",
      " - 0s - loss: 0.0542 - val_loss: 0.0431\n",
      "Epoch 673/1000\n",
      " - 0s - loss: 0.0546 - val_loss: 0.0430\n",
      "Epoch 674/1000\n",
      " - 0s - loss: 0.0545 - val_loss: 0.0425\n",
      "Epoch 675/1000\n",
      " - 0s - loss: 0.0547 - val_loss: 0.0421\n",
      "Epoch 676/1000\n",
      " - 0s - loss: 0.0543 - val_loss: 0.0422\n",
      "Epoch 677/1000\n",
      " - 0s - loss: 0.0544 - val_loss: 0.0422\n",
      "Epoch 678/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.0418\n",
      "Epoch 679/1000\n",
      " - 0s - loss: 0.0545 - val_loss: 0.0411\n",
      "Epoch 680/1000\n",
      " - 0s - loss: 0.0542 - val_loss: 0.0428\n",
      "Epoch 681/1000\n",
      " - 0s - loss: 0.0550 - val_loss: 0.0440\n",
      "Epoch 682/1000\n",
      " - 0s - loss: 0.0550 - val_loss: 0.0428\n",
      "Epoch 683/1000\n",
      " - 0s - loss: 0.0544 - val_loss: 0.0428\n",
      "Epoch 684/1000\n",
      " - 0s - loss: 0.0543 - val_loss: 0.0430\n",
      "Epoch 685/1000\n",
      " - 0s - loss: 0.0537 - val_loss: 0.0419\n",
      "Epoch 686/1000\n",
      " - 0s - loss: 0.0546 - val_loss: 0.0422\n",
      "Epoch 687/1000\n",
      " - 0s - loss: 0.0550 - val_loss: 0.0420\n",
      "Epoch 688/1000\n",
      " - 0s - loss: 0.0548 - val_loss: 0.0431\n",
      "Epoch 689/1000\n",
      " - 0s - loss: 0.0549 - val_loss: 0.0441\n",
      "Epoch 690/1000\n",
      " - 0s - loss: 0.0548 - val_loss: 0.0435\n",
      "Epoch 691/1000\n",
      " - 0s - loss: 0.0536 - val_loss: 0.0432\n",
      "Epoch 692/1000\n",
      " - 0s - loss: 0.0545 - val_loss: 0.0426\n",
      "Epoch 693/1000\n",
      " - 0s - loss: 0.0535 - val_loss: 0.0418\n",
      "Epoch 694/1000\n",
      " - 0s - loss: 0.0536 - val_loss: 0.0430\n",
      "Epoch 695/1000\n",
      " - 0s - loss: 0.0548 - val_loss: 0.0439\n",
      "Epoch 696/1000\n",
      " - 0s - loss: 0.0542 - val_loss: 0.0433\n",
      "Epoch 697/1000\n",
      " - 0s - loss: 0.0555 - val_loss: 0.0436\n",
      "Epoch 698/1000\n",
      " - 0s - loss: 0.0537 - val_loss: 0.0429\n",
      "Epoch 699/1000\n",
      " - 0s - loss: 0.0533 - val_loss: 0.0427\n",
      "Epoch 700/1000\n",
      " - 0s - loss: 0.0537 - val_loss: 0.0418\n",
      "Epoch 701/1000\n",
      " - 0s - loss: 0.0532 - val_loss: 0.0423\n",
      "Epoch 702/1000\n",
      " - 0s - loss: 0.0547 - val_loss: 0.0430\n",
      "Epoch 703/1000\n",
      " - 0s - loss: 0.0548 - val_loss: 0.0429\n",
      "Epoch 704/1000\n",
      " - 0s - loss: 0.0549 - val_loss: 0.0426\n",
      "Epoch 705/1000\n",
      " - 0s - loss: 0.0542 - val_loss: 0.0420\n",
      "Epoch 706/1000\n",
      " - 0s - loss: 0.0546 - val_loss: 0.0420\n",
      "Epoch 707/1000\n",
      " - 0s - loss: 0.0549 - val_loss: 0.0421\n",
      "Epoch 708/1000\n",
      " - 0s - loss: 0.0550 - val_loss: 0.0417\n",
      "Epoch 709/1000\n",
      " - 0s - loss: 0.0538 - val_loss: 0.0417\n",
      "Epoch 710/1000\n",
      " - 0s - loss: 0.0532 - val_loss: 0.0421\n",
      "Epoch 711/1000\n",
      " - 0s - loss: 0.0535 - val_loss: 0.0430\n",
      "Epoch 712/1000\n",
      " - 0s - loss: 0.0540 - val_loss: 0.0428\n",
      "Epoch 713/1000\n",
      " - 0s - loss: 0.0528 - val_loss: 0.0427\n",
      "Epoch 714/1000\n",
      " - 0s - loss: 0.0546 - val_loss: 0.0429\n",
      "Epoch 715/1000\n",
      " - 0s - loss: 0.0544 - val_loss: 0.0434\n",
      "Epoch 716/1000\n",
      " - 0s - loss: 0.0551 - val_loss: 0.0426\n",
      "Epoch 717/1000\n",
      " - 0s - loss: 0.0542 - val_loss: 0.0422\n",
      "Epoch 718/1000\n",
      " - 0s - loss: 0.0533 - val_loss: 0.0426\n",
      "Epoch 719/1000\n",
      " - 0s - loss: 0.0535 - val_loss: 0.0419\n",
      "Epoch 720/1000\n",
      " - 0s - loss: 0.0534 - val_loss: 0.0430\n",
      "Epoch 721/1000\n",
      " - 0s - loss: 0.0531 - val_loss: 0.0436\n",
      "Epoch 722/1000\n",
      " - 0s - loss: 0.0531 - val_loss: 0.0434\n",
      "Epoch 723/1000\n",
      " - 0s - loss: 0.0537 - val_loss: 0.0432\n",
      "Epoch 724/1000\n",
      " - 0s - loss: 0.0529 - val_loss: 0.0431\n",
      "Epoch 725/1000\n",
      " - 0s - loss: 0.0545 - val_loss: 0.0423\n",
      "Epoch 726/1000\n",
      " - 0s - loss: 0.0526 - val_loss: 0.0432\n",
      "Epoch 727/1000\n",
      " - 0s - loss: 0.0534 - val_loss: 0.0434\n",
      "Epoch 728/1000\n",
      " - 0s - loss: 0.0530 - val_loss: 0.0439\n",
      "Epoch 729/1000\n",
      " - 0s - loss: 0.0540 - val_loss: 0.0437\n",
      "Epoch 730/1000\n",
      " - 1s - loss: 0.0538 - val_loss: 0.0426\n",
      "Epoch 731/1000\n",
      " - 1s - loss: 0.0526 - val_loss: 0.0425\n",
      "Epoch 732/1000\n",
      " - 1s - loss: 0.0528 - val_loss: 0.0430\n",
      "Epoch 733/1000\n",
      " - 1s - loss: 0.0534 - val_loss: 0.0424\n",
      "Epoch 734/1000\n",
      " - 1s - loss: 0.0540 - val_loss: 0.0422\n",
      "Epoch 735/1000\n",
      " - 1s - loss: 0.0528 - val_loss: 0.0433\n",
      "Epoch 736/1000\n",
      " - 1s - loss: 0.0541 - val_loss: 0.0442\n",
      "Epoch 737/1000\n",
      " - 0s - loss: 0.0528 - val_loss: 0.0443\n",
      "Epoch 738/1000\n",
      " - 0s - loss: 0.0533 - val_loss: 0.0433\n",
      "Epoch 739/1000\n",
      " - 0s - loss: 0.0537 - val_loss: 0.0432\n",
      "Epoch 740/1000\n",
      " - 0s - loss: 0.0539 - val_loss: 0.0437\n",
      "Epoch 741/1000\n",
      " - 0s - loss: 0.0543 - val_loss: 0.0442\n",
      "Epoch 742/1000\n",
      " - 0s - loss: 0.0523 - val_loss: 0.0440\n",
      "Epoch 743/1000\n",
      " - 0s - loss: 0.0529 - val_loss: 0.0441\n",
      "Epoch 744/1000\n",
      " - 0s - loss: 0.0530 - val_loss: 0.0438\n",
      "Epoch 745/1000\n",
      " - 0s - loss: 0.0522 - val_loss: 0.0430\n",
      "Epoch 746/1000\n",
      " - 0s - loss: 0.0527 - val_loss: 0.0429\n",
      "Epoch 747/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0535 - val_loss: 0.0437\n",
      "Epoch 748/1000\n",
      " - 0s - loss: 0.0538 - val_loss: 0.0429\n",
      "Epoch 749/1000\n",
      " - 0s - loss: 0.0533 - val_loss: 0.0427\n",
      "Epoch 750/1000\n",
      " - 0s - loss: 0.0523 - val_loss: 0.0432\n",
      "Epoch 751/1000\n",
      " - 0s - loss: 0.0525 - val_loss: 0.0432\n",
      "Epoch 752/1000\n",
      " - 0s - loss: 0.0526 - val_loss: 0.0430\n",
      "Epoch 753/1000\n",
      " - 0s - loss: 0.0529 - val_loss: 0.0443\n",
      "Epoch 754/1000\n",
      " - 0s - loss: 0.0527 - val_loss: 0.0440\n",
      "Epoch 755/1000\n",
      " - 0s - loss: 0.0526 - val_loss: 0.0432\n",
      "Epoch 756/1000\n",
      " - 0s - loss: 0.0536 - val_loss: 0.0430\n",
      "Epoch 757/1000\n",
      " - 1s - loss: 0.0538 - val_loss: 0.0425\n",
      "Epoch 758/1000\n",
      " - 0s - loss: 0.0530 - val_loss: 0.0423\n",
      "Epoch 759/1000\n",
      " - 0s - loss: 0.0522 - val_loss: 0.0425\n",
      "Epoch 760/1000\n",
      " - 0s - loss: 0.0526 - val_loss: 0.0431\n",
      "Epoch 761/1000\n",
      " - 0s - loss: 0.0522 - val_loss: 0.0430\n",
      "Epoch 762/1000\n",
      " - 0s - loss: 0.0538 - val_loss: 0.0425\n",
      "Epoch 763/1000\n",
      " - 0s - loss: 0.0531 - val_loss: 0.0430\n",
      "Epoch 764/1000\n",
      " - 0s - loss: 0.0527 - val_loss: 0.0426\n",
      "Epoch 765/1000\n",
      " - 0s - loss: 0.0529 - val_loss: 0.0430\n",
      "Epoch 766/1000\n",
      " - 0s - loss: 0.0532 - val_loss: 0.0435\n",
      "Epoch 767/1000\n",
      " - 0s - loss: 0.0537 - val_loss: 0.0436\n",
      "Epoch 768/1000\n",
      " - 0s - loss: 0.0531 - val_loss: 0.0430\n",
      "Epoch 769/1000\n",
      " - 0s - loss: 0.0534 - val_loss: 0.0437\n",
      "Epoch 770/1000\n",
      " - 0s - loss: 0.0532 - val_loss: 0.0443\n",
      "Epoch 771/1000\n",
      " - 0s - loss: 0.0535 - val_loss: 0.0440\n",
      "Epoch 772/1000\n",
      " - 0s - loss: 0.0530 - val_loss: 0.0441\n",
      "Epoch 773/1000\n",
      " - 0s - loss: 0.0535 - val_loss: 0.0436\n",
      "Epoch 774/1000\n",
      " - 0s - loss: 0.0529 - val_loss: 0.0432\n",
      "Epoch 775/1000\n",
      " - 0s - loss: 0.0525 - val_loss: 0.0428\n",
      "Epoch 776/1000\n",
      " - 0s - loss: 0.0533 - val_loss: 0.0424\n",
      "Epoch 777/1000\n",
      " - 0s - loss: 0.0528 - val_loss: 0.0435\n",
      "Epoch 778/1000\n",
      " - 0s - loss: 0.0529 - val_loss: 0.0437\n",
      "Epoch 779/1000\n",
      " - 0s - loss: 0.0521 - val_loss: 0.0436\n",
      "Epoch 780/1000\n",
      " - 0s - loss: 0.0517 - val_loss: 0.0433\n",
      "Epoch 781/1000\n",
      " - 0s - loss: 0.0514 - val_loss: 0.0436\n",
      "Epoch 782/1000\n",
      " - 0s - loss: 0.0531 - val_loss: 0.0440\n",
      "Epoch 783/1000\n",
      " - 0s - loss: 0.0525 - val_loss: 0.0432\n",
      "Epoch 784/1000\n",
      " - 0s - loss: 0.0513 - val_loss: 0.0423\n",
      "Epoch 785/1000\n",
      " - 0s - loss: 0.0532 - val_loss: 0.0421\n",
      "Epoch 786/1000\n",
      " - 0s - loss: 0.0524 - val_loss: 0.0430\n",
      "Epoch 787/1000\n",
      " - 0s - loss: 0.0538 - val_loss: 0.0439\n",
      "Epoch 788/1000\n",
      " - 0s - loss: 0.0537 - val_loss: 0.0428\n",
      "Epoch 789/1000\n",
      " - 0s - loss: 0.0528 - val_loss: 0.0425\n",
      "Epoch 790/1000\n",
      " - 0s - loss: 0.0525 - val_loss: 0.0434\n",
      "Epoch 791/1000\n",
      " - 0s - loss: 0.0528 - val_loss: 0.0440\n",
      "Epoch 792/1000\n",
      " - 0s - loss: 0.0523 - val_loss: 0.0417\n",
      "Epoch 793/1000\n",
      " - 0s - loss: 0.0524 - val_loss: 0.0422\n",
      "Epoch 794/1000\n",
      " - 0s - loss: 0.0521 - val_loss: 0.0431\n",
      "Epoch 795/1000\n",
      " - 0s - loss: 0.0526 - val_loss: 0.0430\n",
      "Epoch 796/1000\n",
      " - 0s - loss: 0.0527 - val_loss: 0.0432\n",
      "Epoch 797/1000\n",
      " - 0s - loss: 0.0531 - val_loss: 0.0416\n",
      "Epoch 798/1000\n",
      " - 0s - loss: 0.0535 - val_loss: 0.0418\n",
      "Epoch 799/1000\n",
      " - 1s - loss: 0.0536 - val_loss: 0.0432\n",
      "Epoch 800/1000\n",
      " - 0s - loss: 0.0527 - val_loss: 0.0418\n",
      "Epoch 801/1000\n",
      " - 0s - loss: 0.0527 - val_loss: 0.0436\n",
      "Epoch 802/1000\n",
      " - 0s - loss: 0.0524 - val_loss: 0.0428\n",
      "Epoch 803/1000\n",
      " - 0s - loss: 0.0534 - val_loss: 0.0424\n",
      "Epoch 804/1000\n",
      " - 0s - loss: 0.0526 - val_loss: 0.0437\n",
      "Epoch 805/1000\n",
      " - 0s - loss: 0.0539 - val_loss: 0.0450\n",
      "Epoch 806/1000\n",
      " - 0s - loss: 0.0519 - val_loss: 0.0441\n",
      "Epoch 807/1000\n",
      " - 0s - loss: 0.0523 - val_loss: 0.0429\n",
      "Epoch 808/1000\n",
      " - 0s - loss: 0.0522 - val_loss: 0.0429\n",
      "Epoch 809/1000\n",
      " - 0s - loss: 0.0525 - val_loss: 0.0432\n",
      "Epoch 810/1000\n",
      " - 0s - loss: 0.0520 - val_loss: 0.0435\n",
      "Epoch 811/1000\n",
      " - 0s - loss: 0.0525 - val_loss: 0.0442\n",
      "Epoch 812/1000\n",
      " - 0s - loss: 0.0539 - val_loss: 0.0437\n",
      "Epoch 813/1000\n",
      " - 0s - loss: 0.0520 - val_loss: 0.0440\n",
      "Epoch 814/1000\n",
      " - 0s - loss: 0.0520 - val_loss: 0.0442\n",
      "Epoch 815/1000\n",
      " - 0s - loss: 0.0527 - val_loss: 0.0437\n",
      "Epoch 816/1000\n",
      " - 0s - loss: 0.0534 - val_loss: 0.0440\n",
      "Epoch 817/1000\n",
      " - 0s - loss: 0.0516 - val_loss: 0.0438\n",
      "Epoch 818/1000\n",
      " - 0s - loss: 0.0513 - val_loss: 0.0441\n",
      "Epoch 819/1000\n",
      " - 0s - loss: 0.0516 - val_loss: 0.0451\n",
      "Epoch 820/1000\n",
      " - 0s - loss: 0.0517 - val_loss: 0.0453\n",
      "Epoch 821/1000\n",
      " - 0s - loss: 0.0526 - val_loss: 0.0446\n",
      "Epoch 822/1000\n",
      " - 0s - loss: 0.0516 - val_loss: 0.0443\n",
      "Epoch 823/1000\n",
      " - 0s - loss: 0.0529 - val_loss: 0.0447\n",
      "Epoch 824/1000\n",
      " - 0s - loss: 0.0520 - val_loss: 0.0439\n",
      "Epoch 825/1000\n",
      " - 0s - loss: 0.0522 - val_loss: 0.0434\n",
      "Epoch 826/1000\n",
      " - 0s - loss: 0.0519 - val_loss: 0.0432\n",
      "Epoch 827/1000\n",
      " - 0s - loss: 0.0528 - val_loss: 0.0433\n",
      "Epoch 828/1000\n",
      " - 0s - loss: 0.0541 - val_loss: 0.0436\n",
      "Epoch 829/1000\n",
      " - 0s - loss: 0.0537 - val_loss: 0.0440\n",
      "Epoch 830/1000\n",
      " - 0s - loss: 0.0523 - val_loss: 0.0435\n",
      "Epoch 831/1000\n",
      " - 0s - loss: 0.0516 - val_loss: 0.0438\n",
      "Epoch 832/1000\n",
      " - 0s - loss: 0.0526 - val_loss: 0.0436\n",
      "Epoch 833/1000\n",
      " - 0s - loss: 0.0529 - val_loss: 0.0431\n",
      "Epoch 834/1000\n",
      " - 0s - loss: 0.0523 - val_loss: 0.0422\n",
      "Epoch 835/1000\n",
      " - 0s - loss: 0.0518 - val_loss: 0.0428\n",
      "Epoch 836/1000\n",
      " - 0s - loss: 0.0527 - val_loss: 0.0430\n",
      "Epoch 837/1000\n",
      " - 0s - loss: 0.0508 - val_loss: 0.0429\n",
      "Epoch 838/1000\n",
      " - 0s - loss: 0.0516 - val_loss: 0.0436\n",
      "Epoch 839/1000\n",
      " - 0s - loss: 0.0513 - val_loss: 0.0437\n",
      "Epoch 840/1000\n",
      " - 0s - loss: 0.0519 - val_loss: 0.0435\n",
      "Epoch 841/1000\n",
      " - 0s - loss: 0.0514 - val_loss: 0.0433\n",
      "Epoch 842/1000\n",
      " - 0s - loss: 0.0530 - val_loss: 0.0429\n",
      "Epoch 843/1000\n",
      " - 0s - loss: 0.0525 - val_loss: 0.0429\n",
      "Epoch 844/1000\n",
      " - 0s - loss: 0.0515 - val_loss: 0.0424\n",
      "Epoch 845/1000\n",
      " - 0s - loss: 0.0519 - val_loss: 0.0419\n",
      "Epoch 846/1000\n",
      " - 0s - loss: 0.0520 - val_loss: 0.0426\n",
      "Epoch 847/1000\n",
      " - 0s - loss: 0.0522 - val_loss: 0.0431\n",
      "Epoch 848/1000\n",
      " - 0s - loss: 0.0513 - val_loss: 0.0427\n",
      "Epoch 849/1000\n",
      " - 0s - loss: 0.0508 - val_loss: 0.0420\n",
      "Epoch 850/1000\n",
      " - 0s - loss: 0.0523 - val_loss: 0.0417\n",
      "Epoch 851/1000\n",
      " - 0s - loss: 0.0514 - val_loss: 0.0429\n",
      "Epoch 852/1000\n",
      " - 0s - loss: 0.0531 - val_loss: 0.0432\n",
      "Epoch 853/1000\n",
      " - 0s - loss: 0.0518 - val_loss: 0.0427\n",
      "Epoch 854/1000\n",
      " - 0s - loss: 0.0515 - val_loss: 0.0422\n",
      "Epoch 855/1000\n",
      " - 0s - loss: 0.0517 - val_loss: 0.0420\n",
      "Epoch 856/1000\n",
      " - 0s - loss: 0.0527 - val_loss: 0.0429\n",
      "Epoch 857/1000\n",
      " - 0s - loss: 0.0514 - val_loss: 0.0439\n",
      "Epoch 858/1000\n",
      " - 0s - loss: 0.0525 - val_loss: 0.0437\n",
      "Epoch 859/1000\n",
      " - 0s - loss: 0.0517 - val_loss: 0.0436\n",
      "Epoch 860/1000\n",
      " - 0s - loss: 0.0524 - val_loss: 0.0430\n",
      "Epoch 861/1000\n",
      " - 0s - loss: 0.0523 - val_loss: 0.0423\n",
      "Epoch 862/1000\n",
      " - 0s - loss: 0.0519 - val_loss: 0.0419\n",
      "Epoch 863/1000\n",
      " - 0s - loss: 0.0510 - val_loss: 0.0430\n",
      "Epoch 864/1000\n",
      " - 0s - loss: 0.0519 - val_loss: 0.0437\n",
      "Epoch 865/1000\n",
      " - 0s - loss: 0.0517 - val_loss: 0.0422\n",
      "Epoch 866/1000\n",
      " - 0s - loss: 0.0521 - val_loss: 0.0419\n",
      "Epoch 867/1000\n",
      " - 0s - loss: 0.0521 - val_loss: 0.0416\n",
      "Epoch 868/1000\n",
      " - 0s - loss: 0.0506 - val_loss: 0.0426\n",
      "Epoch 869/1000\n",
      " - 0s - loss: 0.0520 - val_loss: 0.0422\n",
      "Epoch 870/1000\n",
      " - 0s - loss: 0.0510 - val_loss: 0.0417\n",
      "Epoch 871/1000\n",
      " - 0s - loss: 0.0517 - val_loss: 0.0417\n",
      "Epoch 872/1000\n",
      " - 0s - loss: 0.0516 - val_loss: 0.0421\n",
      "Epoch 873/1000\n",
      " - 0s - loss: 0.0521 - val_loss: 0.0423\n",
      "Epoch 874/1000\n",
      " - 0s - loss: 0.0517 - val_loss: 0.0426\n",
      "Epoch 875/1000\n",
      " - 1s - loss: 0.0513 - val_loss: 0.0416\n",
      "Epoch 876/1000\n",
      " - 0s - loss: 0.0495 - val_loss: 0.0412\n",
      "Epoch 877/1000\n",
      " - 0s - loss: 0.0491 - val_loss: 0.0364\n",
      "Epoch 878/1000\n",
      " - 0s - loss: 0.0471 - val_loss: 0.0332\n",
      "Epoch 879/1000\n",
      " - 0s - loss: 0.0467 - val_loss: 0.0316\n",
      "Epoch 880/1000\n",
      " - 1s - loss: 0.0448 - val_loss: 0.0309\n",
      "Epoch 881/1000\n",
      " - 0s - loss: 0.0433 - val_loss: 0.0321\n",
      "Epoch 882/1000\n",
      " - 0s - loss: 0.0454 - val_loss: 0.0326\n",
      "Epoch 883/1000\n",
      " - 0s - loss: 0.0451 - val_loss: 0.0318\n",
      "Epoch 884/1000\n",
      " - 0s - loss: 0.0444 - val_loss: 0.0318\n",
      "Epoch 885/1000\n",
      " - 0s - loss: 0.0440 - val_loss: 0.0323\n",
      "Epoch 886/1000\n",
      " - 0s - loss: 0.0434 - val_loss: 0.0332\n",
      "Epoch 887/1000\n",
      " - 0s - loss: 0.0424 - val_loss: 0.0335\n",
      "Epoch 888/1000\n",
      " - 0s - loss: 0.0422 - val_loss: 0.0327\n",
      "Epoch 889/1000\n",
      " - 0s - loss: 0.0435 - val_loss: 0.0326\n",
      "Epoch 890/1000\n",
      " - 0s - loss: 0.0425 - val_loss: 0.0330\n",
      "Epoch 891/1000\n",
      " - 0s - loss: 0.0434 - val_loss: 0.0325\n",
      "Epoch 892/1000\n",
      " - 0s - loss: 0.0433 - val_loss: 0.0322\n",
      "Epoch 893/1000\n",
      " - 0s - loss: 0.0433 - val_loss: 0.0319\n",
      "Epoch 894/1000\n",
      " - 0s - loss: 0.0441 - val_loss: 0.0325\n",
      "Epoch 895/1000\n",
      " - 0s - loss: 0.0424 - val_loss: 0.0333\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0427 - val_loss: 0.0328\n",
      "Epoch 897/1000\n",
      " - 0s - loss: 0.0424 - val_loss: 0.0333\n",
      "Epoch 898/1000\n",
      " - 0s - loss: 0.0438 - val_loss: 0.0336\n",
      "Epoch 899/1000\n",
      " - 0s - loss: 0.0435 - val_loss: 0.0325\n",
      "Epoch 900/1000\n",
      " - 0s - loss: 0.0426 - val_loss: 0.0324\n",
      "Epoch 901/1000\n",
      " - 0s - loss: 0.0417 - val_loss: 0.0329\n",
      "Epoch 902/1000\n",
      " - 0s - loss: 0.0416 - val_loss: 0.0331\n",
      "Epoch 903/1000\n",
      " - 0s - loss: 0.0426 - val_loss: 0.0326\n",
      "Epoch 904/1000\n",
      " - 0s - loss: 0.0425 - val_loss: 0.0323\n",
      "Epoch 905/1000\n",
      " - 0s - loss: 0.0439 - val_loss: 0.0323\n",
      "Epoch 906/1000\n",
      " - 0s - loss: 0.0434 - val_loss: 0.0330\n",
      "Epoch 907/1000\n",
      " - 0s - loss: 0.0430 - val_loss: 0.0323\n",
      "Epoch 908/1000\n",
      " - 0s - loss: 0.0428 - val_loss: 0.0319\n",
      "Epoch 909/1000\n",
      " - 0s - loss: 0.0433 - val_loss: 0.0327\n",
      "Epoch 910/1000\n",
      " - 0s - loss: 0.0442 - val_loss: 0.0324\n",
      "Epoch 911/1000\n",
      " - 0s - loss: 0.0414 - val_loss: 0.0322\n",
      "Epoch 912/1000\n",
      " - 0s - loss: 0.0441 - val_loss: 0.0316\n",
      "Epoch 913/1000\n",
      " - 0s - loss: 0.0409 - val_loss: 0.0320\n",
      "Epoch 914/1000\n",
      " - 0s - loss: 0.0431 - val_loss: 0.0322\n",
      "Epoch 915/1000\n",
      " - 0s - loss: 0.0424 - val_loss: 0.0323\n",
      "Epoch 916/1000\n",
      " - 0s - loss: 0.0420 - val_loss: 0.0326\n",
      "Epoch 917/1000\n",
      " - 0s - loss: 0.0422 - val_loss: 0.0307\n",
      "Epoch 918/1000\n",
      " - 0s - loss: 0.0425 - val_loss: 0.0322\n",
      "Epoch 919/1000\n",
      " - 0s - loss: 0.0421 - val_loss: 0.0309\n",
      "Epoch 920/1000\n",
      " - 0s - loss: 0.0420 - val_loss: 0.0311\n",
      "Epoch 921/1000\n",
      " - 0s - loss: 0.0424 - val_loss: 0.0311\n",
      "Epoch 922/1000\n",
      " - 0s - loss: 0.0426 - val_loss: 0.0308\n",
      "Epoch 923/1000\n",
      " - 0s - loss: 0.0422 - val_loss: 0.0324\n",
      "Epoch 924/1000\n",
      " - 0s - loss: 0.0413 - val_loss: 0.0312\n",
      "Epoch 925/1000\n",
      " - 0s - loss: 0.0414 - val_loss: 0.0314\n",
      "Epoch 926/1000\n",
      " - 0s - loss: 0.0415 - val_loss: 0.0305\n",
      "Epoch 927/1000\n",
      " - 0s - loss: 0.0418 - val_loss: 0.0309\n",
      "Epoch 928/1000\n",
      " - 0s - loss: 0.0425 - val_loss: 0.0295\n",
      "Epoch 929/1000\n",
      " - 0s - loss: 0.0408 - val_loss: 0.0296\n",
      "Epoch 930/1000\n",
      " - 0s - loss: 0.0413 - val_loss: 0.0301\n",
      "Epoch 931/1000\n",
      " - 0s - loss: 0.0424 - val_loss: 0.0294\n",
      "Epoch 932/1000\n",
      " - 0s - loss: 0.0407 - val_loss: 0.0297\n",
      "Epoch 933/1000\n",
      " - 0s - loss: 0.0412 - val_loss: 0.0298\n",
      "Epoch 934/1000\n",
      " - 0s - loss: 0.0436 - val_loss: 0.0298\n",
      "Epoch 935/1000\n",
      " - 0s - loss: 0.0421 - val_loss: 0.0317\n",
      "Epoch 936/1000\n",
      " - 0s - loss: 0.0424 - val_loss: 0.0299\n",
      "Epoch 937/1000\n",
      " - 0s - loss: 0.0411 - val_loss: 0.0320\n",
      "Epoch 938/1000\n",
      " - 0s - loss: 0.0405 - val_loss: 0.0319\n",
      "Epoch 939/1000\n",
      " - 0s - loss: 0.0420 - val_loss: 0.0309\n",
      "Epoch 940/1000\n",
      " - 0s - loss: 0.0421 - val_loss: 0.0314\n",
      "Epoch 941/1000\n",
      " - 0s - loss: 0.0411 - val_loss: 0.0316\n",
      "Epoch 942/1000\n",
      " - 0s - loss: 0.0401 - val_loss: 0.0305\n",
      "Epoch 943/1000\n",
      " - 0s - loss: 0.0411 - val_loss: 0.0297\n",
      "Epoch 944/1000\n",
      " - 0s - loss: 0.0415 - val_loss: 0.0312\n",
      "Epoch 945/1000\n",
      " - 0s - loss: 0.0411 - val_loss: 0.0300\n",
      "Epoch 946/1000\n",
      " - 0s - loss: 0.0431 - val_loss: 0.0304\n",
      "Epoch 947/1000\n",
      " - 0s - loss: 0.0421 - val_loss: 0.0319\n",
      "Epoch 948/1000\n",
      " - 0s - loss: 0.0420 - val_loss: 0.0314\n",
      "Epoch 949/1000\n",
      " - 0s - loss: 0.0430 - val_loss: 0.0324\n",
      "Epoch 950/1000\n",
      " - 0s - loss: 0.0438 - val_loss: 0.0304\n",
      "Epoch 951/1000\n",
      " - 0s - loss: 0.0412 - val_loss: 0.0292\n",
      "Epoch 952/1000\n",
      " - 0s - loss: 0.0423 - val_loss: 0.0288\n",
      "Epoch 953/1000\n",
      " - 0s - loss: 0.0405 - val_loss: 0.0299\n",
      "Epoch 954/1000\n",
      " - 0s - loss: 0.0412 - val_loss: 0.0296\n",
      "Epoch 955/1000\n",
      " - 0s - loss: 0.0414 - val_loss: 0.0297\n",
      "Epoch 956/1000\n",
      " - 0s - loss: 0.0409 - val_loss: 0.0301\n",
      "Epoch 957/1000\n",
      " - 0s - loss: 0.0404 - val_loss: 0.0296\n",
      "Epoch 958/1000\n",
      " - 0s - loss: 0.0407 - val_loss: 0.0294\n",
      "Epoch 959/1000\n",
      " - 0s - loss: 0.0417 - val_loss: 0.0292\n",
      "Epoch 960/1000\n",
      " - 0s - loss: 0.0422 - val_loss: 0.0298\n",
      "Epoch 961/1000\n",
      " - 0s - loss: 0.0406 - val_loss: 0.0288\n",
      "Epoch 962/1000\n",
      " - 0s - loss: 0.0418 - val_loss: 0.0293\n",
      "Epoch 963/1000\n",
      " - 0s - loss: 0.0421 - val_loss: 0.0303\n",
      "Epoch 964/1000\n",
      " - 0s - loss: 0.0423 - val_loss: 0.0317\n",
      "Epoch 965/1000\n",
      " - 0s - loss: 0.0429 - val_loss: 0.0296\n",
      "Epoch 966/1000\n",
      " - 0s - loss: 0.0401 - val_loss: 0.0300\n",
      "Epoch 967/1000\n",
      " - 0s - loss: 0.0395 - val_loss: 0.0305\n",
      "Epoch 968/1000\n",
      " - 0s - loss: 0.0399 - val_loss: 0.0300\n",
      "Epoch 969/1000\n",
      " - 0s - loss: 0.0405 - val_loss: 0.0289\n",
      "Epoch 970/1000\n",
      " - 0s - loss: 0.0411 - val_loss: 0.0286\n",
      "Epoch 971/1000\n",
      " - 0s - loss: 0.0408 - val_loss: 0.0290\n",
      "Epoch 972/1000\n",
      " - 0s - loss: 0.0406 - val_loss: 0.0296\n",
      "Epoch 973/1000\n",
      " - 0s - loss: 0.0432 - val_loss: 0.0303\n",
      "Epoch 974/1000\n",
      " - 0s - loss: 0.0420 - val_loss: 0.0310\n",
      "Epoch 975/1000\n",
      " - 0s - loss: 0.0411 - val_loss: 0.0312\n",
      "Epoch 976/1000\n",
      " - 0s - loss: 0.0406 - val_loss: 0.0292\n",
      "Epoch 977/1000\n",
      " - 0s - loss: 0.0438 - val_loss: 0.0314\n",
      "Epoch 978/1000\n",
      " - 0s - loss: 0.0426 - val_loss: 0.0341\n",
      "Epoch 979/1000\n",
      " - 0s - loss: 0.0401 - val_loss: 0.0285\n",
      "Epoch 980/1000\n",
      " - 0s - loss: 0.0412 - val_loss: 0.0291\n",
      "Epoch 981/1000\n",
      " - 0s - loss: 0.0418 - val_loss: 0.0296\n",
      "Epoch 982/1000\n",
      " - 0s - loss: 0.0413 - val_loss: 0.0305\n",
      "Epoch 983/1000\n",
      " - 0s - loss: 0.0405 - val_loss: 0.0319\n",
      "Epoch 984/1000\n",
      " - 0s - loss: 0.0406 - val_loss: 0.0297\n",
      "Epoch 985/1000\n",
      " - 0s - loss: 0.0402 - val_loss: 0.0296\n",
      "Epoch 986/1000\n",
      " - 0s - loss: 0.0396 - val_loss: 0.0314\n",
      "Epoch 987/1000\n",
      " - 0s - loss: 0.0396 - val_loss: 0.0317\n",
      "Epoch 988/1000\n",
      " - 0s - loss: 0.0414 - val_loss: 0.0310\n",
      "Epoch 989/1000\n",
      " - 0s - loss: 0.0403 - val_loss: 0.0303\n",
      "Epoch 990/1000\n",
      " - 0s - loss: 0.0400 - val_loss: 0.0315\n",
      "Epoch 991/1000\n",
      " - 0s - loss: 0.0404 - val_loss: 0.0292\n",
      "Epoch 992/1000\n",
      " - 0s - loss: 0.0393 - val_loss: 0.0297\n",
      "Epoch 993/1000\n",
      " - 0s - loss: 0.0405 - val_loss: 0.0304\n",
      "Epoch 994/1000\n",
      " - 0s - loss: 0.0398 - val_loss: 0.0287\n",
      "Epoch 995/1000\n",
      " - 0s - loss: 0.0421 - val_loss: 0.0316\n",
      "Epoch 996/1000\n",
      " - 0s - loss: 0.0426 - val_loss: 0.0298\n",
      "Epoch 997/1000\n",
      " - 0s - loss: 0.0416 - val_loss: 0.0343\n",
      "Epoch 998/1000\n",
      " - 0s - loss: 0.0407 - val_loss: 0.0324\n",
      "Epoch 999/1000\n",
      " - 0s - loss: 0.0408 - val_loss: 0.0300\n",
      "Epoch 1000/1000\n",
      " - 0s - loss: 0.0408 - val_loss: 0.0293\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24bc7dffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs = epoch, batch_size = batch_size, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# model.save('LSTM_12_month_42371381890000.h5')\n",
    "# del model\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE MODEL\n",
    "\n",
    "model.save('LSTM_12_month_42371383490000_v2.h5')\n",
    "# model=load_model('LSTM_12_month_42371380040000.h5')\n",
    "# weights=model.get_weights()\n",
    "# print(weights)\n",
    "model.save_weights('weights_42371383490000_v2.hdf5')\n",
    "# model.set_weights(weights)\n",
    "# weights=model.load_weights('weights_42371380040000.hdf5')\n",
    "# model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 6.245\n",
      "MAE = 4.66099\n"
     ]
    }
   ],
   "source": [
    "#Predict the model on test\n",
    "yhat = model.predict(test_X)\n",
    "# print(yhat.shape)\n",
    "# print(test_y.shape)\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = scaler.inverse_transform(yhat)\n",
    "# print(inv_yhat.shape)\n",
    "inv_yhat = inv_yhat[:,:]\n",
    "\n",
    "# invert scaling for actual\n",
    "inv_y = scaler.inverse_transform(test_y)\n",
    "inv_y = inv_y[:,:]\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "#def mean_absolute_error(y_true, y_pred):\n",
    "MAE = mean_absolute_error(inv_y, inv_yhat)\n",
    "print(\"MAE = \"+str(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 8.269\n",
      "MAE Train = 5.88281\n"
     ]
    }
   ],
   "source": [
    "# make a prediction on train\n",
    "yhat_train = model.predict(train_X)\n",
    "\n",
    "# invert scaling for train forecast\n",
    "inv_yhat_train = scaler.inverse_transform(yhat_train)\n",
    "\n",
    "# invert scaling for actual train\n",
    "inv_y_train = scaler.inverse_transform(train_y)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y_train, inv_yhat_train))\n",
    "print('Train RMSE: %.3f' % rmse)\n",
    "\n",
    "#def mean_absolute_error(y_true, y_pred):\n",
    "MAE_train = mean_absolute_error(inv_y_train, inv_yhat_train)\n",
    "print(\"MAE Train = \"+str(MAE_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE Train = 0.728135\n",
      "MAPE Test = 0.221872\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mape\n",
    "# Note LSTM always gives 1 step shifted reponse\n",
    "\n",
    "#test Mape\n",
    "Mape_test1=[]\n",
    "for i in range(n_seq-1):\n",
    "    mape1=(np.abs(inv_y[:,i]-inv_yhat[:,i+1])/(inv_y[:,i]+1))\n",
    "    Mape_test1.append(mape1)\n",
    "#print(Mape_test1)\n",
    "Mape_test=np.mean(Mape_test1)\n",
    "\n",
    "#Mape_test=np.mean(np.abs(inv_y[i]-inv_yhat[i+1])/(inv_y[i]+1))\n",
    "#Mape_train=np.mean(np.abs(inv_y_train[i]-inv_yhat_train[i+1])/(inv_y_train[i]+1))\n",
    "Mape_train=np.mean(np.abs(inv_y_train-inv_yhat_train)/(inv_y_train+1))\n",
    "\n",
    "print(\"MAPE Train = \"+str(Mape_train))\n",
    "print(\"MAPE Test = \"+str(Mape_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24bf56b2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1=pd.DataFrame(inv_y)\n",
    "df2=pd.DataFrame(inv_yhat)\n",
    "value1=df1.values\n",
    "value2=df2.values\n",
    "value1=value1.reshape(n_seq,1)\n",
    "value2=value2.reshape(n_seq,1)\n",
    "plt.figure()\n",
    "plt.plot(value1,'b')\n",
    "plt.plot(value2,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1=pd.DataFrame(inv_y_train[0,:])\n",
    "# df2=pd.DataFrame(inv_yhat_train[0,:])\n",
    "# print(inv_y_train.shape)\n",
    "# value1=df1.values\n",
    "# value2=df2.values\n",
    "# value1=value1.reshape(n_seq,1)\n",
    "# value2=value2.reshape(n_seq,1)\n",
    "# plt.figure()\n",
    "# plt.plot(value1,'b')\n",
    "# plt.plot(value2,'r')\n",
    "# plt.show()\n",
    "\n",
    "# df1=pd.DataFrame(inv_y_train[20,:])\n",
    "# df2=pd.DataFrame(inv_yhat_train[20,:])\n",
    "# print(inv_y_train.shape)\n",
    "# value1=df1.values\n",
    "# value2=df2.values\n",
    "# value1=value1.reshape(n_seq,1)\n",
    "# value2=value2.reshape(n_seq,1)\n",
    "# plt.figure()\n",
    "# plt.plot(value1,'b')\n",
    "# plt.plot(value2,'r')\n",
    "# plt.show()\n",
    "\n",
    "# df1=pd.DataFrame(inv_y_train[40,:])\n",
    "# df2=pd.DataFrame(inv_yhat_train[40,:])\n",
    "# print(inv_y_train.shape)\n",
    "# value1=df1.values\n",
    "# value2=df2.values\n",
    "# value1=value1.reshape(n_seq,1)\n",
    "# value2=value2.reshape(n_seq,1)\n",
    "# plt.figure()\n",
    "# plt.plot(value1,'b')\n",
    "# plt.plot(value2,'r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0, 13.1481\n",
      "26.0, 16.5124\n",
      "15.0, 24.953\n",
      "20.0, 16.8437\n",
      "21.0, 20.3112\n",
      "18.0, 21.8353\n",
      "22.0, 17.0043\n",
      "18.0, 20.9641\n",
      "11.0, 16.3748\n",
      "13.0, 12.9495\n",
      "5.0, 14.0593\n",
      "11.0, 9.35072\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inv_y)):\n",
    "    for j in range(len(inv_y[i])):\n",
    "        print(str(inv_y[i][j])+\", \"+str(inv_yhat[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YearMonth   Oil  Oil_Actual  Oil_Predicted\n",
      "0    201609.0   6.0    6.000000      16.512430\n",
      "1    201610.0  26.0   26.000002      24.952988\n",
      "2    201611.0  15.0   15.000000      16.843731\n",
      "3    201612.0  20.0   20.000000      20.311178\n",
      "4    201701.0  21.0   21.000002      21.835337\n",
      "5    201702.0  18.0   18.000000      17.004261\n",
      "6    201703.0  22.0   22.000000      20.964050\n",
      "7    201704.0  18.0   18.000000      16.374750\n",
      "8    201705.0  11.0   11.000000      12.949542\n",
      "9    201706.0  13.0   13.000001      14.059267\n",
      "10   201707.0   5.0    5.000000       9.350716\n"
     ]
    }
   ],
   "source": [
    "# get test results in CSV\n",
    "df1=pd.DataFrame(inv_y[:,:-1])\n",
    "df1=pd.DataFrame.transpose(df1)\n",
    "df2=pd.DataFrame(inv_yhat[:,1:])\n",
    "df2=pd.DataFrame.transpose(df2)\n",
    "df3=pd.DataFrame(np.array(master_data2.iloc[-n_seq:-1,:]))\n",
    "df3.columns=['YearMonth','Oil']\n",
    "df4=pd.concat([df3,df1,df2],axis=1)\n",
    "df4.columns=['YearMonth','Oil','Oil_Actual','Oil_Predicted']\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('/home/affine/Downloads/Deep_Learning/demo/demo/TGS/Models/Outputs/API_42371383490000_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year-Month</th>\n",
       "      <th>Oil</th>\n",
       "      <th>Actual_Oil</th>\n",
       "      <th>Predicted_Oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201104.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>66.637741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201105.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>64.868294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201106.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>63.447594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201107.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>59.963264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201108.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>54.828442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201109.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>50.677650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>49.517349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201111.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>46.709961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201112.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>38.515247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>201201.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.183018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>201202.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.784601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>201203.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>32.139088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>201204.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.000004</td>\n",
       "      <td>39.151920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>201205.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>36.576019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>201206.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>34.823624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>201207.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>34.905972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>201208.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>33.356747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>201209.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>29.934881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>201210.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>28.991369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>201211.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.319664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>201212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.459740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>201301.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>26.909389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>201302.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>26.715878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>201303.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.000004</td>\n",
       "      <td>26.317896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>201304.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>25.943630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>201305.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.490244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>201306.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.912975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>201307.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.000002</td>\n",
       "      <td>24.282713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>201308.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>23.217405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>201309.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>22.466381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>201403.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.959963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>201404.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>17.411442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>201405.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.853344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>201406.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.895350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>201407.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.902386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>201408.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>17.078627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>201409.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.468069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>201410.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>17.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>201411.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>19.976055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>201412.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>19.182968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>201501.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.000002</td>\n",
       "      <td>17.201424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>201502.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>17.914774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>201503.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>18.692972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>201504.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.643471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>201505.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.191534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>201506.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.943937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>201507.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21.530781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>201508.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>21.853483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>201509.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.293762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>201510.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>18.867237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>201511.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>17.716019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>201512.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.000001</td>\n",
       "      <td>17.082632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>201601.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>17.030140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>201602.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>17.030005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>201603.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.073936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>201604.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>15.599763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>201605.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.730591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>201606.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.854580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>201607.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.148966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>201608.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.640273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year-Month   Oil  Actual_Oil  Predicted_Oil\n",
       "0     201104.0  70.0   70.000000      66.637741\n",
       "1     201105.0  65.0   65.000000      64.868294\n",
       "2     201106.0  71.0   71.000000      63.447594\n",
       "3     201107.0  69.0   69.000000      59.963264\n",
       "4     201108.0  56.0   56.000000      54.828442\n",
       "5     201109.0  51.0   51.000000      50.677650\n",
       "6     201110.0  55.0   55.000000      49.517349\n",
       "7     201111.0  50.0   50.000000      46.709961\n",
       "8     201112.0  43.0   43.000000      38.515247\n",
       "9     201201.0  50.0   50.000000      33.183018\n",
       "10    201202.0  34.0   34.000000      30.784601\n",
       "11    201203.0  40.0   40.000000      32.139088\n",
       "12    201204.0  47.0   47.000004      39.151920\n",
       "13    201205.0  45.0   45.000000      36.576019\n",
       "14    201206.0  39.0   39.000000      34.823624\n",
       "15    201207.0  37.0   37.000000      34.905972\n",
       "16    201208.0   6.0    6.000000      33.356747\n",
       "17    201209.0   5.0    5.000000      29.934881\n",
       "18    201210.0  32.0   32.000000      28.991369\n",
       "19    201211.0   3.0    3.000000      28.319664\n",
       "20    201212.0   0.0    0.000000      27.459740\n",
       "21    201301.0  45.0   45.000000      26.909389\n",
       "22    201302.0  37.0   37.000000      26.715878\n",
       "23    201303.0  42.0   42.000004      26.317896\n",
       "24    201304.0  28.0   28.000000      25.943630\n",
       "25    201305.0  15.0   15.000000      25.490244\n",
       "26    201306.0   0.0    0.000000      24.912975\n",
       "27    201307.0  26.0   26.000002      24.282713\n",
       "28    201308.0  11.0   11.000000      23.217405\n",
       "29    201309.0  29.0   29.000000      22.466381\n",
       "..         ...   ...         ...            ...\n",
       "35    201403.0  19.0   19.000000      19.959963\n",
       "36    201404.0  23.0   23.000000      17.411442\n",
       "37    201405.0  20.0   20.000000      16.853344\n",
       "38    201406.0  17.0   17.000000      17.895350\n",
       "39    201407.0  18.0   18.000000      18.902386\n",
       "40    201408.0  40.0   40.000000      17.078627\n",
       "41    201409.0  17.0   17.000000      16.468069\n",
       "42    201410.0  25.0   25.000000      17.900200\n",
       "43    201411.0  23.0   23.000000      19.976055\n",
       "44    201412.0  22.0   22.000000      19.182968\n",
       "45    201501.0  26.0   26.000002      17.201424\n",
       "46    201502.0  32.0   32.000000      17.914774\n",
       "47    201503.0  22.0   22.000000      18.692972\n",
       "48    201504.0   9.0    9.000000      19.643471\n",
       "49    201505.0  15.0   15.000000      20.191534\n",
       "50    201506.0  14.0   14.000000      20.943937\n",
       "51    201507.0  25.0   25.000000      21.530781\n",
       "52    201508.0  28.0   28.000000      21.853483\n",
       "53    201509.0  23.0   23.000000      20.293762\n",
       "54    201510.0  27.0   27.000000      18.867237\n",
       "55    201511.0  10.0   10.000000      17.716019\n",
       "56    201512.0  13.0   13.000001      17.082632\n",
       "57    201601.0  14.0   14.000000      17.030140\n",
       "58    201602.0   8.0    8.000000      17.030005\n",
       "59    201603.0  15.0   15.000000      16.073936\n",
       "60    201604.0  34.0   34.000000      15.599763\n",
       "61    201605.0  20.0   20.000000      14.730591\n",
       "62    201606.0  18.0   18.000000      13.854580\n",
       "63    201607.0  19.0   19.000000      13.148966\n",
       "64    201608.0   7.0    7.000000      12.640273\n",
       "\n",
       "[65 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(inv_y_train)\n",
    "df11=df1.iloc[:,0]\n",
    "\n",
    "df2=pd.DataFrame(inv_yhat_train)\n",
    "df12=df2.iloc[:,0]\n",
    "\n",
    "df3=pd.DataFrame(np.array(master_data2.iloc[18+12:-n_seq,:]))\n",
    "print(df3.shape)\n",
    "df3.columns=['YearMonth','Oil']\n",
    "\n",
    "df_train=pd.concat([df3,df11,df12], axis=1)\n",
    "df_train1=pd.DataFrame(np.array(df_train))\n",
    "df_train1.columns=[\"Year-Month\",\"Oil\",\"Actual_Oil\",\"Predicted_Oil\"]\n",
    "df_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.to_csv('/home/affine/Downloads/Deep_Learning/demo/demo/TGS/Models/Outputs/API_42371383490000_train_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
